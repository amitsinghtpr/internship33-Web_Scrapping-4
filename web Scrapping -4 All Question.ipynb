{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "623d2cc1",
   "metadata": {},
   "source": [
    "Q1 Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ddc5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re  # import regex\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "347e8777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Chromedriver\n",
    "driver=webdriver.Chrome(r'\"C:\\Users\\amits\\Desktop\\chromedriver_win32\\chromedriver.exe\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd2ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e456580f",
   "metadata": {},
   "source": [
    "**Scrapping the Name of Songs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99b53e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "name=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\")\n",
    "\n",
    "try:\n",
    "    \n",
    "    for i in name[0:30]:\n",
    "        Name.append(i.text.split(\"|\")[0])\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    Name.append('Not Presesnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecf116d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a199458",
   "metadata": {},
   "source": [
    "**Scrapping the Rank Of the Most Viewed Video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e387b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "rank=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\")\n",
    "\n",
    "try:\n",
    "    \n",
    "    for i in rank[0:30]:\n",
    "        Rank.append(i.text.split(\"|\")[0])\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    Name.append('Not Presesnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d44906b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1460482b",
   "metadata": {},
   "source": [
    "**Scrapping Artist Name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a12f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Artist=[]\n",
    "art=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "\n",
    "try:\n",
    "    \n",
    "    for i in art[0:30]:\n",
    "        Artist.append(i.text.split(\"|\")[0])\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    Name.append('Not Presesnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47bcc39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3027054b",
   "metadata": {},
   "source": [
    "**Total views on the Videos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5d9eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Views=[]\n",
    "views=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "\n",
    "try:\n",
    "    \n",
    "    for i in views[0:30]:\n",
    "        Views.append(i.text.split(\"|\")[0])\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    Name.append('Not Presesnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "126a6b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Views)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e684984",
   "metadata": {},
   "source": [
    "**Date of Uploads**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "608d1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date=[]\n",
    "date=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "\n",
    "try:\n",
    "    \n",
    "    for i in date[0:30]:\n",
    "        Date.append(i.text.split(\"|\")[0])\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    Name.append('Not Presesnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e79ce68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0eaf6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>11.74</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.01</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.53</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[15]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.85</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.77</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.70</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>5.02</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[24]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.76</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[25]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.73</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.63</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.61</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.51</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.14</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.78</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[35]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.69</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[36]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.68</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.61</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.61</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.52</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.43</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.40</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[42]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.37</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[43]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.35</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.34</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.31</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.30</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.30</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.29</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.23</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Shake It Off\"[50]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.23</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                               \"Shape of You\"[15]   \n",
       "4    5.                                  \"Bath Song\"[17]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                                \"Uptown Funk\"[24]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[25]   \n",
       "9   10.                          \"Wheels on the Bus\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                      \"Sugar\"[34]   \n",
       "14  15.                                       \"Roar\"[35]   \n",
       "15  16.                             \"Counting Stars\"[36]   \n",
       "16  17.                                     \"Axel F\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                          \"Thinking Out Loud\"[39]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[40]   \n",
       "20  21.                                 \"Dark Horse\"[41]   \n",
       "21  22.                                      \"Faded\"[42]   \n",
       "22  23.                             \"Girls Like You\"[43]   \n",
       "23  24.                                 \"Let Her Go\"[44]   \n",
       "24  25.           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "25  26.                                    \"Perfect\"[46]   \n",
       "26  27.                                   \"Bailando\"[47]   \n",
       "27  28.                                    \"Lean On\"[48]   \n",
       "28  29.          \"Humpty the train on a fruits ride\"[49]   \n",
       "29  30.                               \"Shake It Off\"[50]   \n",
       "\n",
       "                                           Artist  Views               Date  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories  11.74      June 17, 2016  \n",
       "1                                      Luis Fonsi   8.01   January 12, 2017  \n",
       "2                                     LooLoo Kids   6.53    October 8, 2016  \n",
       "3                                      Ed Sheeran   5.85   January 30, 2017  \n",
       "4                      Cocomelon – Nursery Rhymes   5.77        May 2, 2018  \n",
       "5                                     Wiz Khalifa   5.70      April 6, 2015  \n",
       "6                                       ChuChu TV   5.02      March 6, 2014  \n",
       "7                                     Mark Ronson   4.76  November 19, 2014  \n",
       "8                                     Miroshka TV   4.73  February 27, 2018  \n",
       "9                      Cocomelon – Nursery Rhymes   4.63       May 24, 2018  \n",
       "10                                            Psy   4.61      July 15, 2012  \n",
       "11                                     Get Movies   4.51   January 31, 2012  \n",
       "12                                      El Chombo   4.14      April 5, 2018  \n",
       "13                                       Maroon 5   3.78   January 14, 2015  \n",
       "14                                     Katy Perry   3.69  September 5, 2013  \n",
       "15                                    OneRepublic   3.68       May 31, 2013  \n",
       "16                                     Crazy Frog   3.61      June 16, 2009  \n",
       "17                                  Justin Bieber   3.61   October 22, 2015  \n",
       "18                                     Ed Sheeran   3.52    October 7, 2014  \n",
       "19                     Cocomelon – Nursery Rhymes   3.43      June 25, 2018  \n",
       "20                                     Katy Perry   3.40  February 20, 2014  \n",
       "21                                    Alan Walker   3.37   December 3, 2015  \n",
       "22                                       Maroon 5   3.35       May 31, 2018  \n",
       "23                                      Passenger   3.34      July 25, 2012  \n",
       "24                                        Shakira   3.31       June 4, 2010  \n",
       "25                                     Ed Sheeran   3.30   November 9, 2017  \n",
       "26                               Enrique Iglesias   3.30     April 11, 2014  \n",
       "27                                    Major Lazer   3.29     March 22, 2015  \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   3.23   January 26, 2018  \n",
       "29                                   Taylor Swift   3.23    August 18, 2014  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Rank\":Rank,\"Name\":Name,\"Artist\":Artist,\"Views\":Views,\"Date\":Date})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86daf164",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6268284",
   "metadata": {},
   "source": [
    "Q2. Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2c7cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re  # import regex\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700926ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Chromedriver\n",
    "driver=webdriver.Chrome(r'\"C:\\Users\\amits\\Desktop\\chromedriver_win32\\chromedriver.exe\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6006ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='http://www.bcci.tv/'# getting Url\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d46754",
   "metadata": {},
   "outputs": [],
   "source": [
    "butn=driver.find_element(By.XPATH,\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87681bce",
   "metadata": {},
   "source": [
    "**Scrapping Titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adaa29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titles=[]\n",
    "titles=driver.find_elements(By.XPATH,\"//span[@class='matchOrderText ng-binding ng-scope']\")\n",
    "\n",
    "try:\n",
    "    \n",
    "    for i in titles[0:8]:\n",
    "        Titles.append(i.text)\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    Titles.append('Not Presesnt')\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba0c4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89312b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2nd T20I -',\n",
       " '1st Test -',\n",
       " '3rd T20I -',\n",
       " '4th T20I -',\n",
       " '5th T20I -',\n",
       " '2nd Test -',\n",
       " '1st T20I -',\n",
       " '2nd T20I -']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dea4e4",
   "metadata": {},
   "source": [
    "**Scrapping Series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "183ba59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUSTRALIA WOMEN TOUR OF INDIA 2022',\n",
       " 'India Women Need 107 Run(s) to Win from 60 ball(s)',\n",
       " '(20.0 ov)',\n",
       " 'INDIA TOUR OF BANGLADESH TEST SERIES 2022-23',\n",
       " 'AUSTRALIA WOMEN TOUR OF INDIA 2022',\n",
       " 'AUSTRALIA WOMEN TOUR OF INDIA 2022',\n",
       " 'AUSTRALIA WOMEN TOUR OF INDIA 2022',\n",
       " 'INDIA TOUR OF BANGLADESH TEST SERIES 2022-23',\n",
       " 'SRI LANKA TOUR OF INDIA T20 SERIES 2022-23']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series=[]\n",
    "series=driver.find_elements(By.XPATH,\"//span[@class='ng-binding']\")\n",
    "\n",
    "try:\n",
    "    \n",
    "    for i in series[0:9]:\n",
    "        Series.append(i.text)\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    Series.append('Not Presesnt')\n",
    "    \n",
    "\n",
    "\n",
    "time.sleep(5)\n",
    "Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88112b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(20.0 ov)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series.pop(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2332f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596980f",
   "metadata": {},
   "source": [
    "**Scapping Place of Match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95e70416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11 DEC 2022',\n",
       " '14 DEC 2022',\n",
       " '14 DEC 2022',\n",
       " '17 DEC 2022',\n",
       " '20 DEC 2022',\n",
       " '22 DEC 2022',\n",
       " '3 JAN 2023',\n",
       " '5 JAN 2023']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Place=[]\n",
    "place=driver.find_elements(By.XPATH,\"//h5[@class='ng-binding']\")\n",
    "\n",
    "try:\n",
    "    \n",
    "    for i in place[0:9]:\n",
    "        Place.append(i.text)\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    Place.append('Not Presesnt')\n",
    "    \n",
    "\n",
    "\n",
    "time.sleep(5)\n",
    "Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dfb95ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2306c957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LIVE']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time=[]\n",
    "time=driver.find_elements(By.XPATH,\"//div[@class='match-status d-flex align-items-center']\")\n",
    "for i in time:\n",
    "    Time.append(i.text)\n",
    "Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e225f9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LIVE',\n",
       " '9:30 AM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '9:30 AM IST',\n",
       " '7:30 PM IST',\n",
       " '7:30 PM IST']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "try:\n",
    "    \n",
    "    tme=driver.find_elements(By.XPATH,\"//h5[@class='text-right ng-binding']\")\n",
    "    for i in tme[0:7]:\n",
    "        Time.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    Time.append('Not Present')\n",
    "    \n",
    "\n",
    "Time\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a367842c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c6a4af",
   "metadata": {},
   "source": [
    "**Scrapping Date Of the Match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64e396a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zahur Ahmed Chowdhury Stadium,',\n",
       " 'Brabourne - CCI,',\n",
       " 'Brabourne - CCI,',\n",
       " 'Brabourne - CCI,',\n",
       " 'Shere Bangla National Stadium, Mirpur,',\n",
       " 'Wankhede Stadium,',\n",
       " 'Maharashtra Cricket Association Stadium,']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Date=[]\n",
    "place=driver.find_elements(By.XPATH,\"//span[@class='ng-binding ng-scope']\")\n",
    "\n",
    "try:\n",
    "    \n",
    "    for i in place[2:10]:\n",
    "        Date.append(i.text)\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    Date.append('Not Presesnt')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c679e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2nd T20I - DY Patil Stadium, NAVI MUMBAI']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[]\n",
    "place=driver.find_elements(By.XPATH,\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div[1]/div[1]/div/div[5]/div\")\n",
    "for i in place:\n",
    "    x.append(i.text)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7451a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date.insert(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa1b83c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7247b338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2nd T20I - DY Patil Stadium, NAVI MUMBAI'],\n",
       " 'Zahur Ahmed Chowdhury Stadium,',\n",
       " 'Brabourne - CCI,',\n",
       " 'Brabourne - CCI,',\n",
       " 'Brabourne - CCI,',\n",
       " 'Shere Bangla National Stadium, Mirpur,',\n",
       " 'Wankhede Stadium,',\n",
       " 'Maharashtra Cricket Association Stadium,']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f6c05c",
   "metadata": {},
   "source": [
    "**Creating DataFrame Of the Scrapped Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "801277d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Titles</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>[2nd T20I - DY Patil Stadium, NAVI MUMBAI]</td>\n",
       "      <td>11 DEC 2022</td>\n",
       "      <td>LIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st Test -</td>\n",
       "      <td>India Women Need 107 Run(s) to Win from 60 bal...</td>\n",
       "      <td>Zahur Ahmed Chowdhury Stadium,</td>\n",
       "      <td>14 DEC 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH TEST SERIES 2022-23</td>\n",
       "      <td>Brabourne - CCI,</td>\n",
       "      <td>14 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4th T20I -</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>Brabourne - CCI,</td>\n",
       "      <td>17 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5th T20I -</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>Brabourne - CCI,</td>\n",
       "      <td>20 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd Test -</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>22 DEC 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH TEST SERIES 2022-23</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>3 JAN 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>Maharashtra Cricket Association Stadium,</td>\n",
       "      <td>5 JAN 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Titles                                             Series  \\\n",
       "0   2nd T20I -                 AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "1   1st Test -  India Women Need 107 Run(s) to Win from 60 bal...   \n",
       "2   3rd T20I -       INDIA TOUR OF BANGLADESH TEST SERIES 2022-23   \n",
       "3   4th T20I -                 AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "4   5th T20I -                 AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "5   2nd Test -                 AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "6   1st T20I -       INDIA TOUR OF BANGLADESH TEST SERIES 2022-23   \n",
       "7   2nd T20I -         SRI LANKA TOUR OF INDIA T20 SERIES 2022-23   \n",
       "\n",
       "                                        Place         Date         Time  \n",
       "0  [2nd T20I - DY Patil Stadium, NAVI MUMBAI]  11 DEC 2022         LIVE  \n",
       "1              Zahur Ahmed Chowdhury Stadium,  14 DEC 2022  9:30 AM IST  \n",
       "2                            Brabourne - CCI,  14 DEC 2022  7:00 PM IST  \n",
       "3                            Brabourne - CCI,  17 DEC 2022  7:00 PM IST  \n",
       "4                            Brabourne - CCI,  20 DEC 2022  7:00 PM IST  \n",
       "5      Shere Bangla National Stadium, Mirpur,  22 DEC 2022  9:30 AM IST  \n",
       "6                           Wankhede Stadium,   3 JAN 2023  7:30 PM IST  \n",
       "7    Maharashtra Cricket Association Stadium,   5 JAN 2023  7:30 PM IST  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Match Titles\":Titles,\"Series\":Series,\"Place\":Date,\"Date\":Place,\"Time\":Time})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ce9c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420475ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c000ef1a",
   "metadata": {},
   "source": [
    "Q3. Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7015288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re  # import regex\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c74c9902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Chromedriver\n",
    "driver=webdriver.Chrome(r'\"C:\\Users\\amits\\Desktop\\chromedriver_win32\\chromedriver.exe\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b6ba655",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.guru99.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4df0cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10c3f3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['➤ Software Testing',\n",
       " '➤ QTP (Quick Test Professional)',\n",
       " '➤ Selenium',\n",
       " '➤ Mobile App Testing',\n",
       " '➤ Cucumber Testing',\n",
       " '➤ SoapUI',\n",
       " '➤ Agile Testing',\n",
       " '➤ JUnit',\n",
       " '➤ RPA']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrapping testing\n",
    "Testing=[]\n",
    "test=driver.find_elements(By.XPATH,\"//ul[1][@class='menu1']/li/a\")\n",
    "try:\n",
    "    \n",
    "    \n",
    "    for i in test[0:9]:\n",
    "        Testing.append(i.text)\n",
    "\n",
    "except NoSuchElementException:\n",
    "    \n",
    "    \n",
    "    Testing.append('Not Presesnt')\n",
    "\n",
    "Testing  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c323bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['➤ SAP ABAP',\n",
       " '➤ SAP HR/HCM',\n",
       " '➤ SAP FICO',\n",
       " '➤ SAP Basis',\n",
       " '➤ SAP SD',\n",
       " '➤ SAP CRM',\n",
       " '➤ SAP MM',\n",
       " '➤ SAP CO',\n",
       " '➤ SAP Payroll',\n",
       " '➤ SAP BI/BW',\n",
       " '➤ SAP PP',\n",
       " '➤ SAP QM',\n",
       " '➤ SAP HANA',\n",
       " '➤ Crystal Reports',\n",
       " '➤ SAP PI/PO',\n",
       " '➤ SAPUI5',\n",
       " '➤ SAP Security',\n",
       " '➤ SAP BPC',\n",
       " '➤ SAP BODS']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping SAP\n",
    "Sap=[]\n",
    "sap=driver.find_elements(By.XPATH,\"//ul[1][@class='menu1']/li/a\")\n",
    "try:\n",
    "    \n",
    "    for i in sap[12:31]:\n",
    "        Sap.append(i.text)\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    Sap.append('Not Presesnt')\n",
    "Sap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efdfddbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['➤ TensorFlow',\n",
       " '➤ R Programming',\n",
       " '➤ NLTK',\n",
       " '➤ Artificial Intelligence',\n",
       " '➤ Data Science',\n",
       " '➤ Keras',\n",
       " '➤ NumPy',\n",
       " '➤ PyTorch']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping AI\n",
    "AI=[]\n",
    "ai=driver.find_elements(By.XPATH,\"//ul[1][@class='menu1']/li/a\")\n",
    "try:\n",
    "    \n",
    "    for i in ai[31:39]:\n",
    "        AI.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    AI.append('Not Presesnt')    \n",
    "AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46ae68b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['➤ Online Courses',\n",
       " '➤ Reviews',\n",
       " '➤ Excel Tutorials',\n",
       " '➤ Accounting',\n",
       " '➤ Ethical Hacking',\n",
       " '➤ Cloud Computing',\n",
       " '➤ Photoshop CC',\n",
       " '➤ Business Analyst',\n",
       " '➤ Informatica',\n",
       " '➤ Project Management',\n",
       " '➤ VBA',\n",
       " '➤ CCNA',\n",
       " '➤ Jenkins',\n",
       " '➤ Software Engineering',\n",
       " '➤ Blockchain',\n",
       " '➤ Cloud Mining Sites',\n",
       " '➤ Go Programming',\n",
       " '➤ Networking',\n",
       " '➤ Operating System',\n",
       " '➤ Compiler Design',\n",
       " '➤ COBOL',\n",
       " '➤ Embedded Systems',\n",
       " '➤ Algorithms',\n",
       " '➤ Salesforce',\n",
       " '➤ eCommerce Platforms',\n",
       " '➤ Website Monitoring Tools',\n",
       " '➤ IP Blocker Apps',\n",
       " '➤ Best VPNs',\n",
       " '➤ VPN for iPhone']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping Must learn\n",
    "Must_Learn=[]\n",
    "must=driver.find_elements(By.XPATH,\"//ul[1][@class='menu1']/li/a\")\n",
    "try:\n",
    "    \n",
    "\n",
    "    for i in must[40:69]:\n",
    "        Must_Learn.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Must_Learn.append('Not Presesnt')    \n",
    "Must_Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3700e070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['➤ Live Selenium Project',\n",
       " '➤ Live Ecommerce Project',\n",
       " '➤ Live UFT Testing',\n",
       " '➤ Live HP ALM Exercise',\n",
       " '➤ Live Mobile Testing',\n",
       " '➤ Live Security Testing',\n",
       " '➤ Live PHP Project',\n",
       " '➤ Live Scrum(Agile) Testing',\n",
       " '➤ Live Insurance Testing',\n",
       " '➤ Live Payment Gateway',\n",
       " '➤ Live Telecom',\n",
       " '➤ Live Java Project',\n",
       " '➤ Live Python Project']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Live projects\n",
    "Live_Projects=[]\n",
    "live=driver.find_elements(By.XPATH,\"//ul[@class='menu1']/li/a\")\n",
    "try:\n",
    "    \n",
    "    for i in live[10:23]:\n",
    "        Live_Projects.append(i.text)\n",
    "\n",
    "except NoSuchElementException:\n",
    "    Live_Projects.append('Not Presesnt')        \n",
    "Live_Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18f26f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['➤ BigData',\n",
       " '➤ HBase',\n",
       " '➤ MongoDB',\n",
       " '➤ Hive',\n",
       " '➤ Cassandra',\n",
       " '➤ AWS',\n",
       " '➤ Data Warehouse',\n",
       " '➤ DevOps',\n",
       " '➤ Tableau',\n",
       " '➤ MicroStrategy',\n",
       " '➤ OBIEE',\n",
       " '➤ Pentaho',\n",
       " '➤ Power BI',\n",
       " '➤ Qlikview',\n",
       " '➤ Talend',\n",
       " '➤ ZooKeeper',\n",
       " '➤ NiFi']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping big data\n",
    "Big_data=[]\n",
    "data=driver.find_elements(By.XPATH,\"//ul[@class='menu1']/li/a\")\n",
    "for i in data[51:68]:\n",
    "    Big_data.append(i.text)\n",
    "Big_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b5ba569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['➤ VBScript',\n",
       " '➤ Python',\n",
       " '➤ Perl',\n",
       " '➤ Linux',\n",
       " '➤ Javascript',\n",
       " '➤ Apache',\n",
       " '➤ PHP',\n",
       " '➤ AngularJS',\n",
       " '➤ Node.js',\n",
       " '➤ JSP',\n",
       " '➤ Web Services',\n",
       " '➤ C#',\n",
       " '➤ ASP.Net',\n",
       " '➤ Android',\n",
       " '➤ C++',\n",
       " '➤ CodeIgniter',\n",
       " '➤ Kotlin',\n",
       " '➤ ReactJS',\n",
       " '➤ Ruby & Rails',\n",
       " '➤ Scala',\n",
       " '➤ UML',\n",
       " '➤ WPF']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping web\n",
    "Web=[]\n",
    "web=driver.find_elements(By.XPATH,\"//ul[@class='menu1']/li/a\")\n",
    "try:\n",
    "    for i in web[77:99]:\n",
    "        Web.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Web.append('Not Presesnt')\n",
    "        \n",
    "Web\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4f502a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['➤ SQLite', '➤ PostgreSQL', '➤ PL/SQL', '➤ DBMS', '➤ MariaDB', '➤ SQL Server']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping DataBase\n",
    "DataBase=[]\n",
    "data=driver.find_elements(By.XPATH,\"//ul[@class='menu1']/li/a\")\n",
    "try:\n",
    "    for i in data[133:139]:\n",
    "        DataBase.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    DataBase.append('Not Presesnt')\n",
    "        \n",
    "DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0960a601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['➤ HP Quality Center/ALM', '➤ Test Management', '➤ TestLink']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping test managements\n",
    "Test_management=[]\n",
    "test=driver.find_elements(By.XPATH,\"//ul[@class='menu1']/li/a\")\n",
    "try:\n",
    "    \n",
    "    for i in test[99:102]:\n",
    "        Test_management.append(i.text)\n",
    "    \n",
    "except NoSuchElementException:\n",
    "    Test_management.append('Not Presesnt')\n",
    "    \n",
    "Test_management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "880d7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e30ad",
   "metadata": {},
   "source": [
    "Q4.Starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b31a644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re  # import regex\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb6bee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Chromedriver\n",
    "driver=webdriver.Chrome(r'\"C:\\Users\\amits\\Desktop\\chromedriver_win32\\chromedriver.exe\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b26171d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.statisticstimes.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "939c43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f10fc3",
   "metadata": {},
   "source": [
    "**Hovering to Economic page through Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5fc420ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea7438f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ed375d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "56634efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49b7bc6",
   "metadata": {},
   "source": [
    "**Scarpping Rank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "73f065b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rank=[]\n",
    "rank=driver.find_elements(By.XPATH,\"//td[@class='data1']\")\n",
    "for i in rank[0:33]:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5c555d",
   "metadata": {},
   "source": [
    "**Scrapping State**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "781b750e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Gujarat',\n",
       " 'Karnataka',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Andhra Pradesh',\n",
       " 'Telangana',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Chhattisgarh',\n",
       " 'Jharkhand',\n",
       " 'Uttarakhand',\n",
       " 'Jammu & Kashmir',\n",
       " 'Himachal Pradesh',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Sikkim',\n",
       " 'Manipur',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "State=[]\n",
    "state=driver.find_elements(By.XPATH,\"//td[@class='name']\")\n",
    "for i in state[0:33]:\n",
    "    State.append(i.text)\n",
    "    \n",
    "State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f26780",
   "metadata": {},
   "source": [
    "**Scrapping GSDP(19-20) at current price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "418c4355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,632,792',\n",
       " '1,630,208',\n",
       " '1,584,764',\n",
       " '1,502,899',\n",
       " '1,493,127',\n",
       " '1,089,898',\n",
       " '942,586',\n",
       " '862,957',\n",
       " '861,031',\n",
       " '809,592',\n",
       " '781,653',\n",
       " '774,870',\n",
       " '734,163',\n",
       " '530,363',\n",
       " '526,376',\n",
       " '487,805',\n",
       " '315,881',\n",
       " '304,063',\n",
       " '297,204',\n",
       " '245,895',\n",
       " '155,956',\n",
       " '153,845',\n",
       " '73,170',\n",
       " '49,845',\n",
       " '42,114',\n",
       " '34,433',\n",
       " '33,481',\n",
       " '28,723',\n",
       " '27,870',\n",
       " '27,283',\n",
       " '24,603',\n",
       " '22,287',\n",
       " '-']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSDP19_20=[]\n",
    "\n",
    "gsdp=driver.find_elements(By.XPATH,\"//td[@class='data sorting_1']\")\n",
    "for i in gsdp[0:33]:\n",
    "    GSDP19_20.append(i.text)\n",
    "    \n",
    "GSDP19_20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9364fd48",
   "metadata": {},
   "source": [
    "**Scrapping GSDP(18-19) at current Price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84f7b90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '1,845,853',\n",
       " '1,687,818',\n",
       " '-',\n",
       " '1,631,977',\n",
       " '1,253,832',\n",
       " '1,020,989',\n",
       " '972,782',\n",
       " '969,604',\n",
       " '906,672',\n",
       " '-',\n",
       " '856,112',\n",
       " '831,610',\n",
       " '611,804',\n",
       " '574,760',\n",
       " '521,275',\n",
       " '-',\n",
       " '329,180',\n",
       " '328,598',\n",
       " '-',\n",
       " '-',\n",
       " '165,472',\n",
       " '80,449',\n",
       " '55,984',\n",
       " '-',\n",
       " '38,253',\n",
       " '36,572',\n",
       " '32,496',\n",
       " '31,790',\n",
       " '-',\n",
       " '-',\n",
       " '26,503',\n",
       " '-']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdp1819=[]\n",
    "\n",
    "\n",
    "gsp=driver.find_elements(By.XPATH,\"//table[@class='display dataTable'][1]/tbody/tr/td[3]\")\n",
    "for i in gsp[0:33]:\n",
    "    gsdp1819.append(i.text)\n",
    "\n",
    "gsdp1819"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002711f1",
   "metadata": {},
   "source": [
    "**Scrapping Share(18-19)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e848d01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13.94%',\n",
       " '8.63%',\n",
       " '8.39%',\n",
       " '7.96%',\n",
       " '7.91%',\n",
       " '5.77%',\n",
       " '4.99%',\n",
       " '4.57%',\n",
       " '4.56%',\n",
       " '4.29%',\n",
       " '4.14%',\n",
       " '4.10%',\n",
       " '3.89%',\n",
       " '2.81%',\n",
       " '2.79%',\n",
       " '2.58%',\n",
       " '1.67%',\n",
       " '1.61%',\n",
       " '1.57%',\n",
       " '1.30%',\n",
       " '0.83%',\n",
       " '0.81%',\n",
       " '0.39%',\n",
       " '0.26%',\n",
       " '0.22%',\n",
       " '0.18%',\n",
       " '0.18%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.14%',\n",
       " '0.13%',\n",
       " '0.12%',\n",
       " '-']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Share=[]\n",
    "share=driver.find_elements(By.XPATH,\"//table[@class='display dataTable'][1]/tbody/tr/td[5]\")\n",
    "for i in share[0:33]:\n",
    "    Share.append(i.text)\n",
    "    \n",
    "Share"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce69054",
   "metadata": {},
   "source": [
    "**Scrapping GDP($ Billion)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f4aa1457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['399.921',\n",
       " '247.629',\n",
       " '240.726',\n",
       " '228.290',\n",
       " '226.806',\n",
       " '165.556',\n",
       " '143.179',\n",
       " '131.083',\n",
       " '130.791',\n",
       " '122.977',\n",
       " '118.733',\n",
       " '117.703',\n",
       " '111.519',\n",
       " '80.562',\n",
       " '79.957',\n",
       " '74.098',\n",
       " '47.982',\n",
       " '46.187',\n",
       " '45.145',\n",
       " '37.351',\n",
       " '23.690',\n",
       " '23.369',\n",
       " '11.115',\n",
       " '7.571',\n",
       " '6.397',\n",
       " '5.230',\n",
       " '5.086',\n",
       " '4.363',\n",
       " '4.233',\n",
       " '4.144',\n",
       " '3.737',\n",
       " '3.385',\n",
       " '-']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP=[]\n",
    "gdp=driver.find_elements(By.XPATH,\"//table[@class='display dataTable'][1]/tbody/tr/td[6]\")\n",
    "for i in gdp[0:33]:\n",
    "    GDP.append(i.text)\n",
    "    \n",
    "GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260073ca",
   "metadata": {},
   "source": [
    "**Creating DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f83dc98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)-at current Price</th>\n",
       "      <th>GSDP(19-20)-at Current Price</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19)-at current Price  \\\n",
       "0     1                Maharashtra                            -   \n",
       "1     2                 Tamil Nadu                    1,845,853   \n",
       "2     3              Uttar Pradesh                    1,687,818   \n",
       "3     4                    Gujarat                            -   \n",
       "4     5                  Karnataka                    1,631,977   \n",
       "5     6                West Bengal                    1,253,832   \n",
       "6     7                  Rajasthan                    1,020,989   \n",
       "7     8             Andhra Pradesh                      972,782   \n",
       "8     9                  Telangana                      969,604   \n",
       "9    10             Madhya Pradesh                      906,672   \n",
       "10   11                     Kerala                            -   \n",
       "11   12                      Delhi                      856,112   \n",
       "12   13                    Haryana                      831,610   \n",
       "13   14                      Bihar                      611,804   \n",
       "14   15                     Punjab                      574,760   \n",
       "15   16                     Odisha                      521,275   \n",
       "16   17                      Assam                            -   \n",
       "17   18               Chhattisgarh                      329,180   \n",
       "18   19                  Jharkhand                      328,598   \n",
       "19   20                Uttarakhand                            -   \n",
       "20   21            Jammu & Kashmir                            -   \n",
       "21   22           Himachal Pradesh                      165,472   \n",
       "22   23                        Goa                       80,449   \n",
       "23   24                    Tripura                       55,984   \n",
       "24   25                 Chandigarh                            -   \n",
       "25   26                 Puducherry                       38,253   \n",
       "26   27                  Meghalaya                       36,572   \n",
       "27   28                     Sikkim                       32,496   \n",
       "28   29                    Manipur                       31,790   \n",
       "29   30                   Nagaland                            -   \n",
       "30   31          Arunachal Pradesh                            -   \n",
       "31   32                    Mizoram                       26,503   \n",
       "32   33  Andaman & Nicobar Islands                            -   \n",
       "\n",
       "   GSDP(19-20)-at Current Price Share(18-19) GDP($ Billions)  \n",
       "0                     2,632,792       13.94%         399.921  \n",
       "1                     1,630,208        8.63%         247.629  \n",
       "2                     1,584,764        8.39%         240.726  \n",
       "3                     1,502,899        7.96%         228.290  \n",
       "4                     1,493,127        7.91%         226.806  \n",
       "5                     1,089,898        5.77%         165.556  \n",
       "6                       942,586        4.99%         143.179  \n",
       "7                       862,957        4.57%         131.083  \n",
       "8                       861,031        4.56%         130.791  \n",
       "9                       809,592        4.29%         122.977  \n",
       "10                      781,653        4.14%         118.733  \n",
       "11                      774,870        4.10%         117.703  \n",
       "12                      734,163        3.89%         111.519  \n",
       "13                      530,363        2.81%          80.562  \n",
       "14                      526,376        2.79%          79.957  \n",
       "15                      487,805        2.58%          74.098  \n",
       "16                      315,881        1.67%          47.982  \n",
       "17                      304,063        1.61%          46.187  \n",
       "18                      297,204        1.57%          45.145  \n",
       "19                      245,895        1.30%          37.351  \n",
       "20                      155,956        0.83%          23.690  \n",
       "21                      153,845        0.81%          23.369  \n",
       "22                       73,170        0.39%          11.115  \n",
       "23                       49,845        0.26%           7.571  \n",
       "24                       42,114        0.22%           6.397  \n",
       "25                       34,433        0.18%           5.230  \n",
       "26                       33,481        0.18%           5.086  \n",
       "27                       28,723        0.15%           4.363  \n",
       "28                       27,870        0.15%           4.233  \n",
       "29                       27,283        0.14%           4.144  \n",
       "30                       24,603        0.13%           3.737  \n",
       "31                       22,287        0.12%           3.385  \n",
       "32                            -            -               -  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Rank\":Rank,\"State\":State,\"GSDP(18-19)-at current Price\":gsdp1819,\"GSDP(19-20)-at Current Price\":GSDP19_20,\"Share(18-19)\":Share,\"GDP($ Billions)\":GDP})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6c21c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fddff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d31334b9",
   "metadata": {},
   "source": [
    "Q5. Starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e2542cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re  # import regex\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4c74d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Chromedriver\n",
    "driver=webdriver.Chrome(r'\"C:\\Users\\amits\\Desktop\\chromedriver_win32\\chromedriver.exe\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0386cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://github.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "361d3236",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e5c7ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "butn=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "435f35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "but=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4ccff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "73c4da67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tw93 / Pake',\n",
       " 'shinework / photoshot',\n",
       " 'exaloop / codon',\n",
       " 'louislam / uptime-kuma',\n",
       " 'hwchase17 / langchain',\n",
       " 'AUTOMATIC1111 / stable-diffusion-webui',\n",
       " 'charmbracelet / glow',\n",
       " '869413421 / wechatbot',\n",
       " 'TheLastBen / fast-stable-diffusion',\n",
       " 'fuergaosi233 / wechat-chatgpt',\n",
       " 'f / awesome-chatgpt-prompts',\n",
       " 'AutumnWhj / ChatGPT-wechat-bot',\n",
       " 'deepmind / dramatron',\n",
       " 'revanced / revanced-patches',\n",
       " 'tiann / KernelSU',\n",
       " 'humanloop / awesome-chatgpt',\n",
       " 'ange-yaghi / engine-sim',\n",
       " 'iptv-org / iptv',\n",
       " 'pulsar-edit / pulsar',\n",
       " 'UberGuidoZ / Flipper',\n",
       " 'gragland / chatgpt-chrome-extension',\n",
       " 'wechaty / wechaty',\n",
       " 'holbertonschool / Betty',\n",
       " 'Grasscutters / Grasscutter',\n",
       " 'GitHubDaily / GitHubDaily']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Repository Title\n",
    "Repository_titles=[]\n",
    "titles=driver.find_elements(By.XPATH,\"//h1[@class='h3 lh-condensed']/a\")\n",
    "for i in titles:\n",
    "    Repository_titles.append(i.text)\n",
    "    \n",
    "Repository_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c66570da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Repository_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d1d49b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['🤱🏻 A simple way to make any web page a desktop application using Rust. 🤱🏻 很简单的用 Rust 打包网页生成很小的桌面 App',\n",
       " 'A high-performance, zero-overhead, extensible Python compiler using LLVM',\n",
       " 'A fancy self-hosted monitoring tool',\n",
       " '⚡ Building applications with LLMs through composability ⚡',\n",
       " 'Stable Diffusion web UI',\n",
       " 'Render markdown on the CLI, with pizzazz! 💅🏻',\n",
       " '为个人微信接入ChatGPT',\n",
       " 'fast-stable-diffusion, +25-50% speed increase + memory efficient + DreamBooth',\n",
       " 'Use ChatGPT On Wechat via wechaty',\n",
       " 'This repo includes ChatGPT promt curation to use ChatGPT better.',\n",
       " 'ChatGPT for wechat',\n",
       " 'Dramatron uses large language models to generate coherent scripts and screenplays.',\n",
       " '🧩 Patches for ReVanced',\n",
       " 'A Kernel based root solution for Android GKI',\n",
       " 'Curated list of awesome tools, demos, docs for ChatGPT and GPT-3',\n",
       " 'Combustion engine simulator that generates realistic audio.',\n",
       " 'Collection of publicly available IPTV channels from all over the world',\n",
       " 'A Community-led Hyper-Hackable Text Editor',\n",
       " 'Playground (and dump) of stuff I make or modify for the Flipper Zero',\n",
       " 'A ChatGPT Chrome extension. Integrates ChatGPT into every text box on the internet.',\n",
       " 'Conversational RPA SDK for Chatbot Makers',\n",
       " 'Holberton-style C code checker written in Perl',\n",
       " 'A server software reimplementation for a certain anime game.',\n",
       " '坚持分享 GitHub 上高质量、有趣实用的开源技术教程、开发者工具、编程网站、技术资讯。A list cool, interesting projects of GitHub.']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping description\n",
    "Repository_description=[]\n",
    "description=driver.find_elements(By.XPATH,\"//p[@class='col-9 color-fg-muted my-1 pr-4']\")\n",
    "\n",
    "for i in description[0:25]:\n",
    "    Repository_description.append(i.text)\n",
    "    \n",
    "Repository_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0de076c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Repository_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f0a46ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_description.insert(23, None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "839e6b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3,971',\n",
       " '251',\n",
       " '1,959',\n",
       " '24,759',\n",
       " '804',\n",
       " '24,539',\n",
       " '10,937',\n",
       " '546',\n",
       " '2,836',\n",
       " '2,999',\n",
       " '3,027',\n",
       " '711',\n",
       " '230',\n",
       " '2,123',\n",
       " '290',\n",
       " '1,270',\n",
       " '7,002',\n",
       " '59,236',\n",
       " '480',\n",
       " '3,182',\n",
       " '535',\n",
       " '14,111',\n",
       " '685',\n",
       " '11,835',\n",
       " '17,519']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping contributor Count\n",
    "Contributor_count=[]\n",
    "count=driver.find_elements(By.XPATH,\"//div[@class='f6 color-fg-muted mt-2']/a[1]\")\n",
    "for i in count:\n",
    "    Contributor_count.append(i.text)\n",
    "    \n",
    "Contributor_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1e52422a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Contributor_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc88d1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rust',\n",
       " 'TypeScript',\n",
       " 'C++',\n",
       " 'JavaScript',\n",
       " 'Python',\n",
       " 'Python',\n",
       " 'Go',\n",
       " 'Go',\n",
       " 'Python',\n",
       " 'TypeScript',\n",
       " 'TypeScript',\n",
       " 'Jupyter Notebook',\n",
       " 'Kotlin',\n",
       " 'Kotlin',\n",
       " 'C++',\n",
       " 'JavaScript',\n",
       " 'JavaScript',\n",
       " 'Batchfile',\n",
       " 'JavaScript',\n",
       " 'TypeScript',\n",
       " 'Perl',\n",
       " 'Java']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping language\n",
    "Language=[]\n",
    "lan=driver.find_elements(By.XPATH,\"//span[@class='d-inline-block ml-0 mr-3']\")\n",
    "for i in lan:\n",
    "    Language.append(i.text)\n",
    "    \n",
    "Language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d7841afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Language )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6600a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "Language.insert(11,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5878962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Language.insert(14,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "76a82edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Language.insert(23,None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bfd4d95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Titles</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Counts</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tw93 / Pake</td>\n",
       "      <td>🤱🏻 A simple way to make any web page a desktop...</td>\n",
       "      <td>3,971</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shinework / photoshot</td>\n",
       "      <td>A high-performance, zero-overhead, extensible ...</td>\n",
       "      <td>251</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exaloop / codon</td>\n",
       "      <td>A fancy self-hosted monitoring tool</td>\n",
       "      <td>1,959</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>louislam / uptime-kuma</td>\n",
       "      <td>⚡ Building applications with LLMs through comp...</td>\n",
       "      <td>24,759</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hwchase17 / langchain</td>\n",
       "      <td>Stable Diffusion web UI</td>\n",
       "      <td>804</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUTOMATIC1111 / stable-diffusion-webui</td>\n",
       "      <td>Render markdown on the CLI, with pizzazz! 💅🏻</td>\n",
       "      <td>24,539</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>charmbracelet / glow</td>\n",
       "      <td>为个人微信接入ChatGPT</td>\n",
       "      <td>10,937</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>869413421 / wechatbot</td>\n",
       "      <td>fast-stable-diffusion, +25-50% speed increase ...</td>\n",
       "      <td>546</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TheLastBen / fast-stable-diffusion</td>\n",
       "      <td>Use ChatGPT On Wechat via wechaty</td>\n",
       "      <td>2,836</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fuergaosi233 / wechat-chatgpt</td>\n",
       "      <td>This repo includes ChatGPT promt curation to u...</td>\n",
       "      <td>2,999</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>f / awesome-chatgpt-prompts</td>\n",
       "      <td>ChatGPT for wechat</td>\n",
       "      <td>3,027</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AutumnWhj / ChatGPT-wechat-bot</td>\n",
       "      <td>Dramatron uses large language models to genera...</td>\n",
       "      <td>711</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>deepmind / dramatron</td>\n",
       "      <td>🧩 Patches for ReVanced</td>\n",
       "      <td>230</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>revanced / revanced-patches</td>\n",
       "      <td>A Kernel based root solution for Android GKI</td>\n",
       "      <td>2,123</td>\n",
       "      <td>Kotlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tiann / KernelSU</td>\n",
       "      <td>Curated list of awesome tools, demos, docs for...</td>\n",
       "      <td>290</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>humanloop / awesome-chatgpt</td>\n",
       "      <td>Combustion engine simulator that generates rea...</td>\n",
       "      <td>1,270</td>\n",
       "      <td>Kotlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ange-yaghi / engine-sim</td>\n",
       "      <td>Collection of publicly available IPTV channels...</td>\n",
       "      <td>7,002</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>iptv-org / iptv</td>\n",
       "      <td>A Community-led Hyper-Hackable Text Editor</td>\n",
       "      <td>59,236</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pulsar-edit / pulsar</td>\n",
       "      <td>Playground (and dump) of stuff I make or modif...</td>\n",
       "      <td>480</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UberGuidoZ / Flipper</td>\n",
       "      <td>A ChatGPT Chrome extension. Integrates ChatGPT...</td>\n",
       "      <td>3,182</td>\n",
       "      <td>Batchfile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gragland / chatgpt-chrome-extension</td>\n",
       "      <td>Conversational RPA SDK for Chatbot Makers</td>\n",
       "      <td>535</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>wechaty / wechaty</td>\n",
       "      <td>Holberton-style C code checker written in Perl</td>\n",
       "      <td>14,111</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>holbertonschool / Betty</td>\n",
       "      <td>A server software reimplementation for a certa...</td>\n",
       "      <td>685</td>\n",
       "      <td>Perl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Grasscutters / Grasscutter</td>\n",
       "      <td>None</td>\n",
       "      <td>11,835</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GitHubDaily / GitHubDaily</td>\n",
       "      <td>坚持分享 GitHub 上高质量、有趣实用的开源技术教程、开发者工具、编程网站、技术资讯。A...</td>\n",
       "      <td>17,519</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Repository Titles  \\\n",
       "0                              tw93 / Pake   \n",
       "1                    shinework / photoshot   \n",
       "2                          exaloop / codon   \n",
       "3                   louislam / uptime-kuma   \n",
       "4                    hwchase17 / langchain   \n",
       "5   AUTOMATIC1111 / stable-diffusion-webui   \n",
       "6                     charmbracelet / glow   \n",
       "7                    869413421 / wechatbot   \n",
       "8       TheLastBen / fast-stable-diffusion   \n",
       "9            fuergaosi233 / wechat-chatgpt   \n",
       "10             f / awesome-chatgpt-prompts   \n",
       "11          AutumnWhj / ChatGPT-wechat-bot   \n",
       "12                    deepmind / dramatron   \n",
       "13             revanced / revanced-patches   \n",
       "14                        tiann / KernelSU   \n",
       "15             humanloop / awesome-chatgpt   \n",
       "16                 ange-yaghi / engine-sim   \n",
       "17                         iptv-org / iptv   \n",
       "18                    pulsar-edit / pulsar   \n",
       "19                    UberGuidoZ / Flipper   \n",
       "20     gragland / chatgpt-chrome-extension   \n",
       "21                       wechaty / wechaty   \n",
       "22                 holbertonschool / Betty   \n",
       "23              Grasscutters / Grasscutter   \n",
       "24               GitHubDaily / GitHubDaily   \n",
       "\n",
       "                               Repository Description Contributors Counts  \\\n",
       "0   🤱🏻 A simple way to make any web page a desktop...               3,971   \n",
       "1   A high-performance, zero-overhead, extensible ...                 251   \n",
       "2                 A fancy self-hosted monitoring tool               1,959   \n",
       "3   ⚡ Building applications with LLMs through comp...              24,759   \n",
       "4                             Stable Diffusion web UI                 804   \n",
       "5        Render markdown on the CLI, with pizzazz! 💅🏻              24,539   \n",
       "6                                      为个人微信接入ChatGPT              10,937   \n",
       "7   fast-stable-diffusion, +25-50% speed increase ...                 546   \n",
       "8                   Use ChatGPT On Wechat via wechaty               2,836   \n",
       "9   This repo includes ChatGPT promt curation to u...               2,999   \n",
       "10                                 ChatGPT for wechat               3,027   \n",
       "11  Dramatron uses large language models to genera...                 711   \n",
       "12                             🧩 Patches for ReVanced                 230   \n",
       "13       A Kernel based root solution for Android GKI               2,123   \n",
       "14  Curated list of awesome tools, demos, docs for...                 290   \n",
       "15  Combustion engine simulator that generates rea...               1,270   \n",
       "16  Collection of publicly available IPTV channels...               7,002   \n",
       "17         A Community-led Hyper-Hackable Text Editor              59,236   \n",
       "18  Playground (and dump) of stuff I make or modif...                 480   \n",
       "19  A ChatGPT Chrome extension. Integrates ChatGPT...               3,182   \n",
       "20          Conversational RPA SDK for Chatbot Makers                 535   \n",
       "21     Holberton-style C code checker written in Perl              14,111   \n",
       "22  A server software reimplementation for a certa...                 685   \n",
       "23                                               None              11,835   \n",
       "24  坚持分享 GitHub 上高质量、有趣实用的开源技术教程、开发者工具、编程网站、技术资讯。A...              17,519   \n",
       "\n",
       "       Language Used  \n",
       "0               Rust  \n",
       "1         TypeScript  \n",
       "2                C++  \n",
       "3         JavaScript  \n",
       "4             Python  \n",
       "5             Python  \n",
       "6                 Go  \n",
       "7                 Go  \n",
       "8             Python  \n",
       "9         TypeScript  \n",
       "10        TypeScript  \n",
       "11              None  \n",
       "12  Jupyter Notebook  \n",
       "13            Kotlin  \n",
       "14              None  \n",
       "15            Kotlin  \n",
       "16               C++  \n",
       "17        JavaScript  \n",
       "18        JavaScript  \n",
       "19         Batchfile  \n",
       "20        JavaScript  \n",
       "21        TypeScript  \n",
       "22              Perl  \n",
       "23              None  \n",
       "24              Java  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame\n",
    "df=pd.DataFrame({\"Repository Titles\":Repository_titles,\"Repository Description\":Repository_description,\"Contributors Counts\":Contributor_count,\"Language Used\":Language})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "38f79ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1be5761",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ebe3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot=driver.find_element(By.XPATH,\"/html/body/div[3]/div[7]/div/div/div/ul/li[1]/ul/li[2]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2028b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5360d5c",
   "metadata": {},
   "source": [
    "Q7. Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "05766302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d8e99804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Chromedriver\n",
    "driver=webdriver.Chrome(r'\"C:\\Users\\amits\\Desktop\\chromedriver_win32\\chromedriver.exe\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "237854dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximizing window\n",
    "driver.maximize_window()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a318e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the web url via automated chrome window.\n",
    "url='https://www.naukri.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "373ca383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find web element for search job bar.\n",
    "search=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "search.send_keys(\"Data science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4e4d7f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for the loction bar.\n",
    "search_loc=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "search_loc.send_keys(\"Hyderabad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2c548766",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search_butn=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "Search_butn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f01ab985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extacting all the web element having job titles.\n",
    "Name=[]\n",
    "title_tags= driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "try:\n",
    "    for i in title_tags:\n",
    "        Name.append(i.text)\n",
    "\n",
    "except NoSuchElementException:\n",
    "    \n",
    "    \n",
    "    Name.append('Not Presesnt')        \n",
    "len(Name)# checking the length of job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f2c8d72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science Analyst',\n",
       " 'Job Opening For Data Science Manager @ GlobalData(Hyd)',\n",
       " 'Data Science Engineer - Algorithm/Data Pipeline',\n",
       " 'Trainer - Data Science',\n",
       " 'Senior Data Science Analyst',\n",
       " 'Data Science Senior Analyst-Procurement Analytics',\n",
       " 'Data Science Analyst',\n",
       " 'Trainer/program Consultant Data Science with Python',\n",
       " 'Associate Solution Leader - Data Science',\n",
       " 'Hiring For Data Science Manager',\n",
       " 'Data Science Trainer',\n",
       " 'Senior Specialist Data Science',\n",
       " 'CarbyneTech - Data Science Engineer - Machine/Deep Learning Models',\n",
       " 'Data Science Professional',\n",
       " 'Data Science Professional',\n",
       " 'Data Science Lead',\n",
       " 'Data Science Sr Project Manager',\n",
       " 'Data Analyst/ Data Science',\n",
       " 'Research Associate - Data Science',\n",
       " 'Lead/Manager - Data Science']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name # Scrapping all the  20 job detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7115f677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hyderabad/Secunderabad',\n",
       " 'Temp. WFH - Hyderabad/Secunderabad(Kondapur)',\n",
       " 'Temp. WFH - Hyderabad/Secunderabad, Kolkata, Mumbai, Lucknow, Chennai, Ahmedabad, Delhi / NCR, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad(Chandanagar)',\n",
       " 'Hyderabad, Ahmedabad, Bengaluru',\n",
       " 'Hyderabad/Secunderabad',\n",
       " 'Permanent Remote',\n",
       " 'Hyderabad/Secunderabad, Hyderabad',\n",
       " 'Hybrid - Hyderabad/Secunderabad',\n",
       " 'Hybrid - Hyderabad/Secunderabad(Madhapur)',\n",
       " 'Permanent Remote',\n",
       " 'Hyderabad/Secunderabad',\n",
       " 'Hyderabad/Secunderabad',\n",
       " 'Hyderabad/Secunderabad, Mumbai, Pune, Chennai, Delhi / NCR',\n",
       " 'Hyderabad/Secunderabad, Mumbai, Pune, Chennai, Delhi / NCR',\n",
       " 'Hyderabad/Secunderabad, Mumbai, Pune, Chennai, Delhi / NCR',\n",
       " 'Hyderabad/Secunderabad',\n",
       " 'Hyderabad/Secunderabad, Mumbai',\n",
       " 'Hyderabad/Secunderabad',\n",
       " 'Hyderabad/Secunderabad']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting all web elements having company Names\n",
    "job_location=[]\n",
    "location_tags=driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft fs12 lh16 locWdth']\")\n",
    "try:\n",
    "    for i in location_tags:\n",
    "        job_location.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    \n",
    "    \n",
    "    job_location.append('Not Presesnt')    \n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "97aeb09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ira Commerce',\n",
       " 'Globaldata',\n",
       " 'AMSYS IT Services',\n",
       " 'Dr Reddys',\n",
       " 'Otis',\n",
       " 'Accenture',\n",
       " 'Incon Spark India',\n",
       " '2coms consulting',\n",
       " 'Brane Enterprises',\n",
       " 'Evoke Technologies',\n",
       " 'ISDC Projects',\n",
       " 'Dr Reddys',\n",
       " 'CarbyneTech India',\n",
       " 'CliqHR Recruitment Services',\n",
       " 'CliqHR Recruitment Services',\n",
       " 'CliqHR Recruitment Services',\n",
       " 'Brahma Consulting Group',\n",
       " 'Anlage Infotech (I) Pvt. Ltd.',\n",
       " 'Recodeminds',\n",
       " 'Brahma Consulting Group']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets extract all web elements having company Names\n",
    "company_name=[]\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6837236a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data science\\nSenior Analyst\\nAnalytical\\nProgramming\\nAnalytics\\nPython',\n",
       " 'Text Analytics\\nmachine learning\\ndeep learning\\nNLP\\ndata science\\npython\\ncaffe\\nreinforcement learning',\n",
       " 'data analysis\\nData Pipeline\\ndata structures\\ndata acquisition',\n",
       " 'Data Science\\nexcel\\npython\\nstats\\nMl',\n",
       " 'data science\\nMachine learning\\nMarketing operations\\npower bi\\ndata mapping\\ndata visualization\\nIndividual Contributor\\nForecasting',\n",
       " 'Procurement\\nAnalytical\\nSpend analysis\\nBudgeting\\nAnalytics\\nProcurement Analytics',\n",
       " 'Data Science\\nData mining\\nmachine learning\\nText Mining',\n",
       " 'Data Science\\nTraining Delivery\\nPython',\n",
       " 'data scientist\\nNLP\\nNatural Language Processing\\nComputer Vision\\nMachine Learning\\nDeep Learning',\n",
       " 'deep learning\\ncomputer vision\\nAWS SageMaker\\nLSTMs\\nAzure\\nKeras\\nCNNs\\nmodel tuning',\n",
       " 'Data Science\\nStatistics\\nPython\\nTraining\\nIot Application Development\\nData Mining\\nAnalytics\\nR Program',\n",
       " 'advanced analytics\\nData analysis\\nChannel marketing\\ndata science\\nDigital sales\\nDoctor\\nManagement\\nMonitoring',\n",
       " 'Brand Management\\nAdvertising\\nMarketing\\nTensorflow\\nR\\nBig Data\\nNumpy\\nPython',\n",
       " 'Data Science\\nPython\\ncommunication\\nanalytical\\nAzure\\nSki\\nPandas\\nHTML',\n",
       " 'Data Science\\nSki\\nData Analytics\\nNumpy\\nanalytical\\nPowerPoint\\nAzure\\ncommunication',\n",
       " 'Data Science\\nanalytical\\nR\\nwritten\\ndata mining\\nverbal communication\\nPython\\nmachine learning',\n",
       " 'Relationship management\\nData analysis\\ndata science\\nProject management\\nProcess improvement\\nConsulting\\nIssue resolution\\nSubject Matter Expert',\n",
       " 'data science\\nTableau\\npython\\nData Analysis\\nSPSS',\n",
       " 'Computer science\\nE-learning\\nSAN\\nData analysis\\nFrench\\nAnalytical\\nResearch Associate\\nInternship',\n",
       " 'Data analysis\\ndata science\\nSAS\\nConsulting\\nPredictive modeling\\nData mining\\nForecasting\\nOperations']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Skills=[]\n",
    "skil=driver.find_elements(By.XPATH,\"//ul[@class='tags has-description']\")\n",
    "try:\n",
    "    for i in skil:\n",
    "        Skills.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "    \n",
    "    \n",
    "    Skills.append('Not Presesnt')\n",
    "Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e0d51727",
   "metadata": {},
   "outputs": [],
   "source": [
    "Naukri=pd.DataFrame({\"Designation\":Name,\"Company Name\":company_name,\"Location Of Job\":job_location,\"Skill They are hire for\":Skills})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6334959e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location Of Job</th>\n",
       "      <th>Skill They are hire for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Ira Commerce</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>data science\\nSenior Analyst\\nAnalytical\\nProg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job Opening For Data Science Manager @ GlobalD...</td>\n",
       "      <td>Globaldata</td>\n",
       "      <td>Temp. WFH - Hyderabad/Secunderabad(Kondapur)</td>\n",
       "      <td>Text Analytics\\nmachine learning\\ndeep learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Engineer - Algorithm/Data Pipeline</td>\n",
       "      <td>AMSYS IT Services</td>\n",
       "      <td>Temp. WFH - Hyderabad/Secunderabad, Kolkata, M...</td>\n",
       "      <td>data analysis\\nData Pipeline\\ndata structures\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trainer - Data Science</td>\n",
       "      <td>Dr Reddys</td>\n",
       "      <td>Hyderabad/Secunderabad(Chandanagar)</td>\n",
       "      <td>Data Science\\nexcel\\npython\\nstats\\nMl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Science Analyst</td>\n",
       "      <td>Otis</td>\n",
       "      <td>Hyderabad, Ahmedabad, Bengaluru</td>\n",
       "      <td>data science\\nMachine learning\\nMarketing oper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Senior Analyst-Procurement Analytics</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Procurement\\nAnalytical\\nSpend analysis\\nBudge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Incon Spark India</td>\n",
       "      <td>Permanent Remote</td>\n",
       "      <td>Data Science\\nData mining\\nmachine learning\\nT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trainer/program Consultant Data Science with P...</td>\n",
       "      <td>2coms consulting</td>\n",
       "      <td>Hyderabad/Secunderabad, Hyderabad</td>\n",
       "      <td>Data Science\\nTraining Delivery\\nPython</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Associate Solution Leader - Data Science</td>\n",
       "      <td>Brane Enterprises</td>\n",
       "      <td>Hybrid - Hyderabad/Secunderabad</td>\n",
       "      <td>data scientist\\nNLP\\nNatural Language Processi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Science Manager</td>\n",
       "      <td>Evoke Technologies</td>\n",
       "      <td>Hybrid - Hyderabad/Secunderabad(Madhapur)</td>\n",
       "      <td>deep learning\\ncomputer vision\\nAWS SageMaker\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Science Trainer</td>\n",
       "      <td>ISDC Projects</td>\n",
       "      <td>Permanent Remote</td>\n",
       "      <td>Data Science\\nStatistics\\nPython\\nTraining\\nIo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Senior Specialist Data Science</td>\n",
       "      <td>Dr Reddys</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>advanced analytics\\nData analysis\\nChannel mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CarbyneTech - Data Science Engineer - Machine/...</td>\n",
       "      <td>CarbyneTech India</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Brand Management\\nAdvertising\\nMarketing\\nTens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Science Professional</td>\n",
       "      <td>CliqHR Recruitment Services</td>\n",
       "      <td>Hyderabad/Secunderabad, Mumbai, Pune, Chennai,...</td>\n",
       "      <td>Data Science\\nPython\\ncommunication\\nanalytica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Science Professional</td>\n",
       "      <td>CliqHR Recruitment Services</td>\n",
       "      <td>Hyderabad/Secunderabad, Mumbai, Pune, Chennai,...</td>\n",
       "      <td>Data Science\\nSki\\nData Analytics\\nNumpy\\nanal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Science Lead</td>\n",
       "      <td>CliqHR Recruitment Services</td>\n",
       "      <td>Hyderabad/Secunderabad, Mumbai, Pune, Chennai,...</td>\n",
       "      <td>Data Science\\nanalytical\\nR\\nwritten\\ndata min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Science Sr Project Manager</td>\n",
       "      <td>Brahma Consulting Group</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Relationship management\\nData analysis\\ndata s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Analyst/ Data Science</td>\n",
       "      <td>Anlage Infotech (I) Pvt. Ltd.</td>\n",
       "      <td>Hyderabad/Secunderabad, Mumbai</td>\n",
       "      <td>data science\\nTableau\\npython\\nData Analysis\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Research Associate - Data Science</td>\n",
       "      <td>Recodeminds</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Computer science\\nE-learning\\nSAN\\nData analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lead/Manager - Data Science</td>\n",
       "      <td>Brahma Consulting Group</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Data analysis\\ndata science\\nSAS\\nConsulting\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Designation  \\\n",
       "0                                Data Science Analyst   \n",
       "1   Job Opening For Data Science Manager @ GlobalD...   \n",
       "2     Data Science Engineer - Algorithm/Data Pipeline   \n",
       "3                              Trainer - Data Science   \n",
       "4                         Senior Data Science Analyst   \n",
       "5   Data Science Senior Analyst-Procurement Analytics   \n",
       "6                                Data Science Analyst   \n",
       "7   Trainer/program Consultant Data Science with P...   \n",
       "8            Associate Solution Leader - Data Science   \n",
       "9                     Hiring For Data Science Manager   \n",
       "10                               Data Science Trainer   \n",
       "11                     Senior Specialist Data Science   \n",
       "12  CarbyneTech - Data Science Engineer - Machine/...   \n",
       "13                          Data Science Professional   \n",
       "14                          Data Science Professional   \n",
       "15                                  Data Science Lead   \n",
       "16                    Data Science Sr Project Manager   \n",
       "17                         Data Analyst/ Data Science   \n",
       "18                  Research Associate - Data Science   \n",
       "19                        Lead/Manager - Data Science   \n",
       "\n",
       "                     Company Name  \\\n",
       "0                    Ira Commerce   \n",
       "1                      Globaldata   \n",
       "2               AMSYS IT Services   \n",
       "3                       Dr Reddys   \n",
       "4                            Otis   \n",
       "5                       Accenture   \n",
       "6               Incon Spark India   \n",
       "7                2coms consulting   \n",
       "8               Brane Enterprises   \n",
       "9              Evoke Technologies   \n",
       "10                  ISDC Projects   \n",
       "11                      Dr Reddys   \n",
       "12              CarbyneTech India   \n",
       "13    CliqHR Recruitment Services   \n",
       "14    CliqHR Recruitment Services   \n",
       "15    CliqHR Recruitment Services   \n",
       "16        Brahma Consulting Group   \n",
       "17  Anlage Infotech (I) Pvt. Ltd.   \n",
       "18                    Recodeminds   \n",
       "19        Brahma Consulting Group   \n",
       "\n",
       "                                      Location Of Job  \\\n",
       "0                              Hyderabad/Secunderabad   \n",
       "1        Temp. WFH - Hyderabad/Secunderabad(Kondapur)   \n",
       "2   Temp. WFH - Hyderabad/Secunderabad, Kolkata, M...   \n",
       "3                 Hyderabad/Secunderabad(Chandanagar)   \n",
       "4                     Hyderabad, Ahmedabad, Bengaluru   \n",
       "5                              Hyderabad/Secunderabad   \n",
       "6                                    Permanent Remote   \n",
       "7                   Hyderabad/Secunderabad, Hyderabad   \n",
       "8                     Hybrid - Hyderabad/Secunderabad   \n",
       "9           Hybrid - Hyderabad/Secunderabad(Madhapur)   \n",
       "10                                   Permanent Remote   \n",
       "11                             Hyderabad/Secunderabad   \n",
       "12                             Hyderabad/Secunderabad   \n",
       "13  Hyderabad/Secunderabad, Mumbai, Pune, Chennai,...   \n",
       "14  Hyderabad/Secunderabad, Mumbai, Pune, Chennai,...   \n",
       "15  Hyderabad/Secunderabad, Mumbai, Pune, Chennai,...   \n",
       "16                             Hyderabad/Secunderabad   \n",
       "17                     Hyderabad/Secunderabad, Mumbai   \n",
       "18                             Hyderabad/Secunderabad   \n",
       "19                             Hyderabad/Secunderabad   \n",
       "\n",
       "                              Skill They are hire for  \n",
       "0   data science\\nSenior Analyst\\nAnalytical\\nProg...  \n",
       "1   Text Analytics\\nmachine learning\\ndeep learnin...  \n",
       "2   data analysis\\nData Pipeline\\ndata structures\\...  \n",
       "3              Data Science\\nexcel\\npython\\nstats\\nMl  \n",
       "4   data science\\nMachine learning\\nMarketing oper...  \n",
       "5   Procurement\\nAnalytical\\nSpend analysis\\nBudge...  \n",
       "6   Data Science\\nData mining\\nmachine learning\\nT...  \n",
       "7             Data Science\\nTraining Delivery\\nPython  \n",
       "8   data scientist\\nNLP\\nNatural Language Processi...  \n",
       "9   deep learning\\ncomputer vision\\nAWS SageMaker\\...  \n",
       "10  Data Science\\nStatistics\\nPython\\nTraining\\nIo...  \n",
       "11  advanced analytics\\nData analysis\\nChannel mar...  \n",
       "12  Brand Management\\nAdvertising\\nMarketing\\nTens...  \n",
       "13  Data Science\\nPython\\ncommunication\\nanalytica...  \n",
       "14  Data Science\\nSki\\nData Analytics\\nNumpy\\nanal...  \n",
       "15  Data Science\\nanalytical\\nR\\nwritten\\ndata min...  \n",
       "16  Relationship management\\nData analysis\\ndata s...  \n",
       "17  data science\\nTableau\\npython\\nData Analysis\\n...  \n",
       "18  Computer science\\nE-learning\\nSAN\\nData analys...  \n",
       "19  Data analysis\\ndata science\\nSAS\\nConsulting\\n...  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Naukri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a1bd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0061a0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fab517f3",
   "metadata": {},
   "source": [
    "Q8. Start From here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4d0f5e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re  # import regex\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8f08ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Chromedriver\n",
    "driver=webdriver.Chrome(r'\"C:\\Users\\amits\\Desktop\\chromedriver_win32\\chromedriver.exe\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "45d78f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0aeb535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9cff5a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Da Vinci Code,The',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Angels and Demons',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Fifty Shades Darker',\n",
       " 'Twilight',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Fifty Shades Freed',\n",
       " 'Lost Symbol,The',\n",
       " 'New Moon',\n",
       " 'Deception Point',\n",
       " 'Eclipse',\n",
       " 'Lovely Bones,The',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Digital Fortress',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Breaking Dawn',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Gruffalo,The',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Kite Runner,The',\n",
       " 'One Day',\n",
       " 'Thousand Splendid Suns,A',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Atonement',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'World According to Clarkson,The',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Sound of Laughter,The',\n",
       " 'Life of Pi',\n",
       " 'Billy Connolly',\n",
       " 'Child Called It,A',\n",
       " \"Gruffalo's Child,The\",\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'Birdsong',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Labyrinth',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Help,The',\n",
       " 'Man and Boy',\n",
       " 'Memoirs of a Geisha',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'Island,The',\n",
       " 'PS, I Love You',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Broker,The',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Chocolat',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " \"My Sister's Keeper\",\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Dear Fatty',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Hannibal',\n",
       " 'Lord of the Rings,The',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " 'Notes from a Small Island',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " \"Jamie's Italy\",\n",
       " 'I Can Make You Thin',\n",
       " 'Down Under',\n",
       " 'Summons,The',\n",
       " 'Small Island',\n",
       " 'Nigella Express',\n",
       " 'Brick Lane',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Room on the Broom',\n",
       " 'About a Boy',\n",
       " 'My Booky Wook',\n",
       " 'God Delusion,The',\n",
       " '\"Beano\" Annual,The',\n",
       " 'White Teeth',\n",
       " 'House at Riverton,The',\n",
       " 'Book Thief,The',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Ghost,The',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titles=[]           #Scrapping Titles\n",
    "titles=driver.find_elements(By.XPATH,\"//td[2][@class='left']\")\n",
    "for i in titles:\n",
    "    Titles.append(i.text)\n",
    "    \n",
    "Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1a7a35ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Meyer, Stephenie',\n",
       " 'Larsson, Stieg',\n",
       " 'James, E. L.',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Sebold, Alice',\n",
       " 'Haddon, Mark',\n",
       " 'Brown, Dan',\n",
       " 'Bryson, Bill',\n",
       " 'Larsson, Stieg',\n",
       " 'Meyer, Stephenie',\n",
       " 'Carle, Eric',\n",
       " 'Donaldson, Julia',\n",
       " 'Oliver, Jamie',\n",
       " 'Hosseini, Khaled',\n",
       " 'Nicholls, David',\n",
       " 'Hosseini, Khaled',\n",
       " 'Larsson, Stieg',\n",
       " 'Niffenegger, Audrey',\n",
       " 'McEwan, Ian',\n",
       " 'Fielding, Helen',\n",
       " 'Clarkson, Jeremy',\n",
       " 'Bernieres, Louis de',\n",
       " 'Kay, Peter',\n",
       " 'Martel, Yann',\n",
       " 'Stephenson, Pamela',\n",
       " 'Pelzer, Dave',\n",
       " 'Donaldson, Julia',\n",
       " 'McCourt, Frank',\n",
       " 'Faulks, Sebastian',\n",
       " 'Pullman, Philip',\n",
       " 'Mosse, Kate',\n",
       " 'Rowling, J.K.',\n",
       " 'Stockett, Kathryn',\n",
       " 'Parsons, Tony',\n",
       " 'Golden, Arthur',\n",
       " 'McCall Smith, Alexander',\n",
       " 'Hislop, Victoria',\n",
       " 'Ahern, Cecelia',\n",
       " 'McKeith, Gillian',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " 'Rowling, J.K.',\n",
       " 'Grisham, John',\n",
       " 'Atkins, Robert C.',\n",
       " 'Pullman, Philip',\n",
       " 'Truss, Lynne',\n",
       " 'Smith, Delia',\n",
       " 'Harris, Joanne',\n",
       " 'Boyne, John',\n",
       " 'Picoult, Jodi',\n",
       " 'Pullman, Philip',\n",
       " 'Lee, Harper',\n",
       " 'Gray, John',\n",
       " 'French, Dawn',\n",
       " 'Lewycka, Marina',\n",
       " 'Harris, Thomas',\n",
       " 'Tolkien, J. R. R.',\n",
       " 'Moore, Michael',\n",
       " 'Rubenfeld, Jed',\n",
       " 'Osbourne, Sharon',\n",
       " 'Coelho, Paulo',\n",
       " \"O'Grady, Paul\",\n",
       " 'Bryson, Bill',\n",
       " 'Oliver, Jamie',\n",
       " 'Fielding, Helen',\n",
       " 'Oliver, Jamie',\n",
       " 'McKenna, Paul',\n",
       " 'Bryson, Bill',\n",
       " 'Grisham, John',\n",
       " 'Levy, Andrea',\n",
       " 'Lawson, Nigella',\n",
       " 'Ali, Monica',\n",
       " 'Edwards, Kim',\n",
       " 'Donaldson, Julia',\n",
       " 'Hornby, Nick',\n",
       " 'Brand, Russell',\n",
       " 'Dawkins, Richard',\n",
       " '0',\n",
       " 'Smith, Zadie',\n",
       " 'Morton, Kate',\n",
       " 'Zusak, Markus',\n",
       " 'Binchy, Maeve',\n",
       " 'Harris, Robert',\n",
       " 'Oliver, Jamie',\n",
       " 'Collins, Suzanne',\n",
       " 'Pelzer, Dave',\n",
       " 'Oliver, Jamie']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Authors Name\n",
    "Authors=[]\n",
    "authors=driver.find_elements(By.XPATH,\"//td[3][@class='left']\")\n",
    "for i in authors:\n",
    "    Authors.append(i.text)\n",
    "    \n",
    "Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2d5cc396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,094,805',\n",
       " '4,475,152',\n",
       " '4,200,654',\n",
       " '4,179,479',\n",
       " '3,758,936',\n",
       " '3,583,215',\n",
       " '3,484,047',\n",
       " '3,377,906',\n",
       " '3,193,946',\n",
       " '2,950,264',\n",
       " '2,479,784',\n",
       " '2,315,405',\n",
       " '2,233,570',\n",
       " '2,193,928',\n",
       " '2,183,031',\n",
       " '2,152,737',\n",
       " '2,062,145',\n",
       " '2,052,876',\n",
       " '2,005,598',\n",
       " '1,979,552',\n",
       " '1,928,900',\n",
       " '1,852,919',\n",
       " '1,814,784',\n",
       " '1,787,118',\n",
       " '1,783,535',\n",
       " '1,781,269',\n",
       " '1,743,266',\n",
       " '1,629,119',\n",
       " '1,616,068',\n",
       " '1,583,992',\n",
       " '1,555,135',\n",
       " '1,546,886',\n",
       " '1,539,428',\n",
       " '1,508,205',\n",
       " '1,489,403',\n",
       " '1,352,318',\n",
       " '1,310,207',\n",
       " '1,310,176',\n",
       " '1,231,957',\n",
       " '1,217,712',\n",
       " '1,208,711',\n",
       " '1,204,058',\n",
       " '1,184,967',\n",
       " '1,181,503',\n",
       " '1,181,093',\n",
       " '1,153,181',\n",
       " '1,132,336',\n",
       " '1,130,802',\n",
       " '1,126,337',\n",
       " '1,115,549',\n",
       " '1,108,328',\n",
       " '1,107,379',\n",
       " '1,104,403',\n",
       " '1,092,349',\n",
       " '1,090,847',\n",
       " '1,087,262',\n",
       " '1,054,196',\n",
       " '1,037,160',\n",
       " '1,023,688',\n",
       " '1,015,956',\n",
       " '1,009,873',\n",
       " '1,004,414',\n",
       " '1,003,780',\n",
       " '1,002,314',\n",
       " '998,213',\n",
       " '992,846',\n",
       " '986,753',\n",
       " '986,115',\n",
       " '970,509',\n",
       " '967,466',\n",
       " '963,353',\n",
       " '962,515',\n",
       " '959,496',\n",
       " '956,114',\n",
       " '945,640',\n",
       " '931,312',\n",
       " '925,425',\n",
       " '924,695',\n",
       " '906,968',\n",
       " '905,086',\n",
       " '890,847',\n",
       " '869,671',\n",
       " '869,659',\n",
       " '862,602',\n",
       " '856,540',\n",
       " '845,858',\n",
       " '842,535',\n",
       " '828,215',\n",
       " '820,563',\n",
       " '816,907',\n",
       " '816,585',\n",
       " '815,586',\n",
       " '814,370',\n",
       " '809,641',\n",
       " '808,900',\n",
       " '807,311',\n",
       " '794,201',\n",
       " '792,187',\n",
       " '791,507',\n",
       " '791,095']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Volumes\n",
    "Volumes=[]\n",
    "vol=driver.find_elements(By.XPATH,\"//td[4][@class='left']\")\n",
    "for i in vol:\n",
    "    Volumes.append(i.text)\n",
    "    \n",
    "Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b333b7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Pan Macmillan',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Quercus',\n",
       " 'Little, Brown Book',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Bloomsbury',\n",
       " 'Hodder & Stoughton',\n",
       " 'Bloomsbury',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Canongate',\n",
       " 'HarperCollins',\n",
       " 'Orion',\n",
       " 'Pan Macmillan',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Penguin',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Headline',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Profile Books Group',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Random House Childrens Books G',\n",
       " 'Hodder & Stoughton',\n",
       " 'Scholastic Ltd.',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Headline',\n",
       " 'Little, Brown Book',\n",
       " 'HarperCollins',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Random House',\n",
       " 'Headline',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Hodder & Stoughton',\n",
       " 'Transworld',\n",
       " 'D.C. Thomson',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Transworld',\n",
       " 'Orion',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Publisher\n",
    "Publisher=[]\n",
    "publisher=driver.find_elements(By.XPATH,\"//td[5][@class='left']\")\n",
    "for i in publisher:\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "Publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bebbe133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Romance & Sagas',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Popular Science',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Picture Books',\n",
       " 'Picture Books',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Humour: Collections & General',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Biography: The Arts',\n",
       " 'Autobiography: General',\n",
       " 'Picture Books',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Fitness & Diet',\n",
       " 'General & Literary Fiction',\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Fitness & Diet',\n",
       " 'Young Adult Fiction',\n",
       " 'Usage & Writing Guides',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Popular Culture & Media: General Interest',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'Current Affairs & Issues',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Travel Writing',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'National & Regional Cuisine',\n",
       " 'Fitness & Diet',\n",
       " 'Travel Writing',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Picture Books',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Popular Science',\n",
       " \"Children's Annuals\",\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'Young Adult Fiction',\n",
       " 'Biography: General',\n",
       " 'Food & Drink: General']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Genre\n",
    "Genre=[]\n",
    "genre=driver.find_elements(By.XPATH,\"//td[@class='last left']\")\n",
    "for i in genre:\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a3107b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DatFrame\n",
    "df=pd.DataFrame({\"Book Name\":Titles,\"Author Name\":Authors,\"Volume Sold\":Volumes,\"Publisher\":Publisher,\"Genre\":Genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5f056c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d1d5a",
   "metadata": {},
   "source": [
    "Q9. Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e3011c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re  # import regex\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ed9c8c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Chromedriver\n",
    "driver=webdriver.Chrome(r'\"C:\\Users\\amits\\Desktop\\chromedriver_win32\\chromedriver.exe\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "100c1c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c33e7d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "473da939",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a1113fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game of Thrones',\n",
       " 'Stranger Things',\n",
       " 'The Walking Dead',\n",
       " '13 Reasons Why',\n",
       " 'The 100',\n",
       " 'Orange Is the New Black',\n",
       " 'Riverdale',\n",
       " \"Grey's Anatomy\",\n",
       " 'The Flash',\n",
       " 'Arrow',\n",
       " 'Money Heist',\n",
       " 'The Big Bang Theory',\n",
       " 'Black Mirror',\n",
       " 'Sherlock',\n",
       " 'Vikings',\n",
       " 'Pretty Little Liars',\n",
       " 'The Vampire Diaries',\n",
       " 'American Horror Story',\n",
       " 'Breaking Bad',\n",
       " 'Lucifer',\n",
       " 'Supernatural',\n",
       " 'Prison Break',\n",
       " 'How to Get Away with Murder',\n",
       " 'Teen Wolf',\n",
       " 'The Simpsons',\n",
       " 'Once Upon a Time',\n",
       " 'Narcos',\n",
       " 'Daredevil',\n",
       " 'Friends',\n",
       " 'How I Met Your Mother',\n",
       " 'Suits',\n",
       " 'Mr. Robot',\n",
       " 'The Originals',\n",
       " 'Supergirl',\n",
       " 'Gossip Girl',\n",
       " 'Sense8',\n",
       " 'Gotham',\n",
       " 'Westworld',\n",
       " 'Jessica Jones',\n",
       " 'Modern Family',\n",
       " 'Rick and Morty',\n",
       " 'Shadowhunters',\n",
       " 'The End of the F***ing World',\n",
       " 'House of Cards',\n",
       " 'Dark',\n",
       " 'Elite',\n",
       " 'Sex Education',\n",
       " 'Shameless',\n",
       " 'New Girl',\n",
       " 'Agents of S.H.I.E.L.D.',\n",
       " 'You',\n",
       " 'Dexter',\n",
       " 'Fear the Walking Dead',\n",
       " 'Family Guy',\n",
       " 'The Blacklist',\n",
       " 'Lost',\n",
       " 'Peaky Blinders',\n",
       " 'House',\n",
       " 'Quantico',\n",
       " 'Orphan Black',\n",
       " 'Homeland',\n",
       " 'Blindspot',\n",
       " \"DC's Legends of Tomorrow\",\n",
       " \"The Handmaid's Tale\",\n",
       " 'Chilling Adventures of Sabrina',\n",
       " 'The Good Doctor',\n",
       " 'Jane the Virgin',\n",
       " 'Glee',\n",
       " 'South Park',\n",
       " 'Brooklyn Nine-Nine',\n",
       " 'Under the Dome',\n",
       " 'The Umbrella Academy',\n",
       " 'True Detective',\n",
       " 'The OA',\n",
       " 'Desperate Housewives',\n",
       " 'Better Call Saul',\n",
       " 'Bates Motel',\n",
       " 'The Punisher',\n",
       " 'Atypical',\n",
       " 'Dynasty',\n",
       " 'This Is Us',\n",
       " 'The Good Place',\n",
       " 'Iron Fist',\n",
       " 'The Rain',\n",
       " 'Mindhunter',\n",
       " 'Revenge',\n",
       " 'Luke Cage',\n",
       " 'Scandal',\n",
       " 'The Defenders',\n",
       " 'Big Little Lies',\n",
       " 'Insatiable',\n",
       " 'The Mentalist',\n",
       " 'The Crown',\n",
       " 'Chernobyl',\n",
       " 'iZombie',\n",
       " 'Reign',\n",
       " 'A Series of Unfortunate Events',\n",
       " 'Criminal Minds',\n",
       " 'Scream: The TV Series',\n",
       " 'The Haunting of Hill House']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Names=[]\n",
    "name=driver.find_elements(By.XPATH,\"//div[@class='lister-item mode-detail']/div[2]/h3/a\")\n",
    "for i in name:\n",
    "    Names.append(i.text)\n",
    "    \n",
    "Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "070810e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011–2019)',\n",
       " '(2016– )',\n",
       " '(2010–2022)',\n",
       " '(2017–2020)',\n",
       " '(2014–2020)',\n",
       " '(2013–2019)',\n",
       " '(2017– )',\n",
       " '(2005– )',\n",
       " '(2014–2023)',\n",
       " '(2012–2020)',\n",
       " '(2017–2021)',\n",
       " '(2007–2019)',\n",
       " '(2011–2019)',\n",
       " '(2010–2017)',\n",
       " '(2013–2020)',\n",
       " '(2010–2017)',\n",
       " '(2009–2017)',\n",
       " '(2011– )',\n",
       " '(2008–2013)',\n",
       " '(2016–2021)',\n",
       " '(2005–2020)',\n",
       " '(2005–2017)',\n",
       " '(2014–2020)',\n",
       " '(2011–2017)',\n",
       " '(1989– )',\n",
       " '(2011–2018)',\n",
       " '(2015–2017)',\n",
       " '(2015–2018)',\n",
       " '(1994–2004)',\n",
       " '(2005–2014)',\n",
       " '(2011–2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2018)',\n",
       " '(2015–2021)',\n",
       " '(2007–2012)',\n",
       " '(2015–2018)',\n",
       " '(2014–2019)',\n",
       " '(2016–2022)',\n",
       " '(2015–2019)',\n",
       " '(2009–2020)',\n",
       " '(2013– )',\n",
       " '(2016–2019)',\n",
       " '(2017–2019)',\n",
       " '(2013–2018)',\n",
       " '(2017–2020)',\n",
       " '(2018– )',\n",
       " '(2019– )',\n",
       " '(2011–2021)',\n",
       " '(2011–2018)',\n",
       " '(2013–2020)',\n",
       " '(2018– )',\n",
       " '(2006–2013)',\n",
       " '(2015– )',\n",
       " '(1999– )',\n",
       " '(2013– )',\n",
       " '(2004–2010)',\n",
       " '(2013–2022)',\n",
       " '(2004–2012)',\n",
       " '(2015–2018)',\n",
       " '(2013–2017)',\n",
       " '(2011–2020)',\n",
       " '(2015–2020)',\n",
       " '(2016–2022)',\n",
       " '(2017– )',\n",
       " '(2018–2020)',\n",
       " '(2017– )',\n",
       " '(2014–2019)',\n",
       " '(2009–2015)',\n",
       " '(1997– )',\n",
       " '(2013–2021)',\n",
       " '(2013–2015)',\n",
       " '(2019–2023)',\n",
       " '(2014–2019)',\n",
       " '(2016–2019)',\n",
       " '(2004–2012)',\n",
       " '(2015–2022)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2017–2021)',\n",
       " '(2017–2022)',\n",
       " '(2016–2022)',\n",
       " '(2016–2020)',\n",
       " '(2017–2018)',\n",
       " '(2018–2020)',\n",
       " '(2017–2019)',\n",
       " '(2011–2015)',\n",
       " '(2016–2018)',\n",
       " '(2012–2018)',\n",
       " '(2017)',\n",
       " '(2017–2019)',\n",
       " '(2018–2019)',\n",
       " '(2008–2015)',\n",
       " '(2016– )',\n",
       " '(2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2005– )',\n",
       " '(2015–2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Year_span=[]\n",
    "year=driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "for i in year:\n",
    "    Year_span.append(i.text)\n",
    "    \n",
    "Year_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bbdabcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Genre=[]\n",
    "genre=driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "for i in genre:\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c015a7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '41 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '55 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '30 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '22 min',\n",
       " '55 min',\n",
       " '45 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '43 min',\n",
       " '50 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '58 min',\n",
       " '330 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '50 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '572 min']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUN_time=[]\n",
    "run=driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "for i in run:\n",
    "    RUN_time.append(i.text)\n",
    "    \n",
    "RUN_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fd9d9716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '8.7',\n",
       " '8.1',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '8.1',\n",
       " '6.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.8',\n",
       " '9.1',\n",
       " '8.5',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8',\n",
       " '9.5',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '7.7',\n",
       " '8.8',\n",
       " '8.6',\n",
       " '8.9',\n",
       " '8.3',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.3',\n",
       " '6.2',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '7.8',\n",
       " '8.5',\n",
       " '7.9',\n",
       " '8.5',\n",
       " '9.1',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '7.3',\n",
       " '8.4',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '6.8',\n",
       " '8.2',\n",
       " '8',\n",
       " '8.3',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '6.7',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '6.8',\n",
       " '8.4',\n",
       " '7.4',\n",
       " '8.1',\n",
       " '7.9',\n",
       " '6.8',\n",
       " '8.7',\n",
       " '8.4',\n",
       " '6.5',\n",
       " '7.9',\n",
       " '8.9',\n",
       " '7.8',\n",
       " '7.6',\n",
       " '8.9',\n",
       " '8.1',\n",
       " '8.5',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '6.4',\n",
       " '6.3',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.3',\n",
       " '7.7',\n",
       " '7.2',\n",
       " '8.5',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '9.4',\n",
       " '7.8',\n",
       " '7.4',\n",
       " '7.8',\n",
       " '8.1',\n",
       " '7.1',\n",
       " '8.6']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating=[]\n",
    "rating=driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-widget']/div/span[2]\")\n",
    "for i in rating:\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2dc31f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,091,510',\n",
       " '1,180,981',\n",
       " '989,751',\n",
       " '293,022',\n",
       " '252,205',\n",
       " '303,075',\n",
       " '145,576',\n",
       " '309,150',\n",
       " '346,450',\n",
       " '432,089',\n",
       " '476,373',\n",
       " '807,640',\n",
       " '546,126',\n",
       " '924,833',\n",
       " '532,039',\n",
       " '168,111',\n",
       " '322,461',\n",
       " '319,882',\n",
       " '1,874,496',\n",
       " '324,688',\n",
       " '445,969',\n",
       " '535,616',\n",
       " '152,356',\n",
       " '149,045',\n",
       " '407,651',\n",
       " '225,532',\n",
       " '422,249',\n",
       " '441,023',\n",
       " '993,491',\n",
       " '683,474',\n",
       " '411,102',\n",
       " '387,915',\n",
       " '136,692',\n",
       " '124,463',\n",
       " '175,549',\n",
       " '155,061',\n",
       " '231,016',\n",
       " '505,251',\n",
       " '215,271',\n",
       " '430,916',\n",
       " '520,256',\n",
       " '64,152',\n",
       " '191,092',\n",
       " '504,806',\n",
       " '386,008',\n",
       " '79,784',\n",
       " '280,920',\n",
       " '243,549',\n",
       " '225,206',\n",
       " '217,721',\n",
       " '240,856',\n",
       " '725,641',\n",
       " '130,517',\n",
       " '340,178',\n",
       " '249,930',\n",
       " '553,721',\n",
       " '547,072',\n",
       " '465,154',\n",
       " '61,284',\n",
       " '111,575',\n",
       " '342,161',\n",
       " '74,428',\n",
       " '105,283',\n",
       " '237,422',\n",
       " '95,906',\n",
       " '95,658',\n",
       " '51,198',\n",
       " '149,035',\n",
       " '369,759',\n",
       " '316,438',\n",
       " '107,066',\n",
       " '248,454',\n",
       " '570,766',\n",
       " '105,508',\n",
       " '129,674',\n",
       " '526,218',\n",
       " '108,787',\n",
       " '236,736',\n",
       " '89,540',\n",
       " '22,895',\n",
       " '144,524',\n",
       " '160,893',\n",
       " '131,807',\n",
       " '37,629',\n",
       " '289,005',\n",
       " '120,518',\n",
       " '131,898',\n",
       " '74,368',\n",
       " '108,541',\n",
       " '199,753',\n",
       " '29,145',\n",
       " '185,817',\n",
       " '217,372',\n",
       " '749,321',\n",
       " '68,746',\n",
       " '50,215',\n",
       " '61,532',\n",
       " '198,558',\n",
       " '41,595',\n",
       " '245,488']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Votes=[]\n",
    "vote=driver.find_elements(By.XPATH,\"//div[@class='lister-item-content']/p[4]/span[2]\")\n",
    "for i in vote:\n",
    "    Votes.append(i.text)\n",
    "    \n",
    "Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5bb2bdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,091,510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,180,981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>989,751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>293,022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>252,205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>61,532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>198,558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>245,488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,091,510  \n",
       "1    51 min     8.7  1,180,981  \n",
       "2    44 min     8.1    989,751  \n",
       "3    60 min     7.5    293,022  \n",
       "4    43 min     7.6    252,205  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     50,215  \n",
       "96   50 min     7.8     61,532  \n",
       "97   42 min     8.1    198,558  \n",
       "98   45 min     7.1     41,595  \n",
       "99  572 min     8.6    245,488  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Name\":Names,\"Year Span\":Year_span,\"Genre\":Genre,\"Run Time\":RUN_time,\"Ratings\":Rating,\"Votes\":Votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170f359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "02b4c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a63ec36",
   "metadata": {},
   "source": [
    "Q10. Starts Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6c5e8aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re  # import regex\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "29bb8b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Chromedriver\n",
    "driver=webdriver.Chrome(r'\"C:\\Users\\amits\\Desktop\\chromedriver_win32\\chromedriver.exe\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a62e73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0bcfac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://archive.ics.uci.edu/ml/index.php'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ce2103db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_butn=driver.find_element(By.XPATH,\"/html/body/table[2]/tbody/tr/td/span/b/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "829cfa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "49c47180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abalone',\n",
       " 'Adult',\n",
       " 'Annealing',\n",
       " 'Anonymous Microsoft Web Data',\n",
       " 'Arrhythmia',\n",
       " 'Artificial Characters',\n",
       " 'Audiology (Original)',\n",
       " 'Audiology (Standardized)',\n",
       " 'Auto MPG',\n",
       " 'Automobile',\n",
       " 'Badges',\n",
       " 'Balance Scale',\n",
       " 'Balloons',\n",
       " 'Breast Cancer',\n",
       " 'Breast Cancer Wisconsin (Original)',\n",
       " 'Breast Cancer Wisconsin (Prognostic)',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Pittsburgh Bridges',\n",
       " 'Car Evaluation',\n",
       " 'Census Income',\n",
       " 'Chess (King-Rook vs. King-Knight)',\n",
       " 'Chess (King-Rook vs. King-Pawn)',\n",
       " 'Chess (King-Rook vs. King)',\n",
       " 'Chess (Domain Theories)',\n",
       " 'Bach Chorales',\n",
       " 'Connect-4',\n",
       " 'Credit Approval',\n",
       " 'Japanese Credit Screening',\n",
       " 'Computer Hardware',\n",
       " 'Contraceptive Method Choice',\n",
       " 'Covertype',\n",
       " 'Cylinder Bands',\n",
       " 'Dermatology',\n",
       " 'Diabetes',\n",
       " 'DGP2 - The Second Data Generation Program',\n",
       " 'Document Understanding',\n",
       " 'EBL Domain Theories',\n",
       " 'Echocardiogram',\n",
       " 'Ecoli',\n",
       " 'Flags',\n",
       " 'Function Finding',\n",
       " 'Glass Identification',\n",
       " \"Haberman's Survival\",\n",
       " 'Hayes-Roth',\n",
       " 'Heart Disease',\n",
       " 'Hepatitis',\n",
       " 'Horse Colic',\n",
       " 'ICU',\n",
       " 'Image Segmentation',\n",
       " 'Internet Advertisements',\n",
       " 'Ionosphere',\n",
       " 'Iris',\n",
       " 'ISOLET',\n",
       " 'Kinship',\n",
       " 'Labor Relations',\n",
       " 'LED Display Domain',\n",
       " 'Lenses',\n",
       " 'Letter Recognition',\n",
       " 'Liver Disorders',\n",
       " 'Logic Theorist',\n",
       " 'Lung Cancer',\n",
       " 'Lymphography',\n",
       " 'Mechanical Analysis',\n",
       " 'Meta-data',\n",
       " 'Mobile Robots',\n",
       " 'Molecular Biology (Promoter Gene Sequences)',\n",
       " 'Molecular Biology (Protein Secondary Structure)',\n",
       " 'Molecular Biology (Splice-junction Gene Sequences)',\n",
       " \"MONK's Problems\",\n",
       " 'Moral Reasoner',\n",
       " 'Multiple Features',\n",
       " 'Mushroom',\n",
       " 'Musk (Version 1)',\n",
       " 'Musk (Version 2)',\n",
       " 'Nursery',\n",
       " 'Othello Domain Theory',\n",
       " 'Page Blocks Classification',\n",
       " 'Optical Recognition of Handwritten Digits',\n",
       " 'Pen-Based Recognition of Handwritten Digits',\n",
       " 'Post-Operative Patient',\n",
       " 'Primary Tumor',\n",
       " 'Prodigy',\n",
       " 'Qualitative Structure Activity Relationships',\n",
       " 'Quadruped Mammals',\n",
       " 'Servo',\n",
       " 'Shuttle Landing Control',\n",
       " 'Solar Flare',\n",
       " 'Soybean (Large)',\n",
       " 'Soybean (Small)',\n",
       " 'Challenger USA Space Shuttle O-Ring',\n",
       " 'Low Resolution Spectrometer',\n",
       " 'Spambase',\n",
       " 'SPECT Heart',\n",
       " 'SPECTF Heart',\n",
       " 'Sponge',\n",
       " 'Statlog Project',\n",
       " 'Student Loan Relational',\n",
       " 'Teaching Assistant Evaluation',\n",
       " 'Tic-Tac-Toe Endgame',\n",
       " 'Thyroid Disease',\n",
       " 'Trains',\n",
       " 'University',\n",
       " 'Congressional Voting Records',\n",
       " 'Water Treatment Plant',\n",
       " 'Waveform Database Generator (Version 1)',\n",
       " 'Waveform Database Generator (Version 2)',\n",
       " 'Wine',\n",
       " 'Yeast',\n",
       " 'Zoo',\n",
       " 'Undocumented',\n",
       " 'Twenty Newsgroups',\n",
       " 'Australian Sign Language signs',\n",
       " 'Australian Sign Language signs (High Quality)',\n",
       " 'US Census Data (1990)',\n",
       " 'Census-Income (KDD)',\n",
       " 'Coil 1999 Competition Data',\n",
       " 'Corel Image Features',\n",
       " 'E. Coli Genes',\n",
       " 'EEG Database',\n",
       " 'El Nino',\n",
       " 'Entree Chicago Recommendation Data',\n",
       " 'CMU Face Images',\n",
       " 'Insurance Company Benchmark (COIL 2000)',\n",
       " 'Internet Usage Data',\n",
       " 'IPUMS Census Database',\n",
       " 'Japanese Vowels',\n",
       " 'KDD Cup 1998 Data',\n",
       " 'KDD Cup 1999 Data',\n",
       " 'M. Tuberculosis Genes',\n",
       " 'Movie',\n",
       " 'MSNBC.com Anonymous Web Data',\n",
       " 'NSF Research Award Abstracts 1990-2003',\n",
       " 'Pioneer-1 Mobile Robot Data',\n",
       " 'Pseudo Periodic Synthetic Time Series',\n",
       " 'Reuters-21578 Text Categorization Collection',\n",
       " 'Robot Execution Failures',\n",
       " 'Synthetic Control Chart Time Series',\n",
       " 'Syskill and Webert Web Page Ratings',\n",
       " 'UNIX User Data',\n",
       " 'Volcanoes on Venus - JARtool experiment',\n",
       " 'Statlog (Australian Credit Approval)',\n",
       " 'Statlog (German Credit Data)',\n",
       " 'Statlog (Heart)',\n",
       " 'Statlog (Landsat Satellite)',\n",
       " 'Statlog (Image Segmentation)',\n",
       " 'Statlog (Shuttle)',\n",
       " 'Statlog (Vehicle Silhouettes)',\n",
       " 'Connectionist Bench (Nettalk Corpus)',\n",
       " 'Connectionist Bench (Sonar, Mines vs. Rocks)',\n",
       " 'Connectionist Bench (Vowel Recognition - Deterding Data)',\n",
       " 'Economic Sanctions',\n",
       " 'Protein Data',\n",
       " 'Cloud',\n",
       " 'CalIt2 Building People Counts',\n",
       " 'Dodgers Loop Sensor',\n",
       " 'Poker Hand',\n",
       " 'MAGIC Gamma Telescope',\n",
       " 'UJI Pen Characters',\n",
       " 'Mammographic Mass',\n",
       " 'Forest Fires',\n",
       " 'Reuters Transcribed Subset',\n",
       " 'Bag of Words',\n",
       " 'Concrete Compressive Strength',\n",
       " 'Hill-Valley',\n",
       " 'Arcene',\n",
       " 'Dexter',\n",
       " 'Dorothea',\n",
       " 'Gisette',\n",
       " 'Madelon',\n",
       " 'Ozone Level Detection',\n",
       " 'Abscisic Acid Signaling Network',\n",
       " 'Parkinsons',\n",
       " 'Character Trajectories',\n",
       " 'Blood Transfusion Service Center',\n",
       " 'UJI Pen Characters (Version 2)',\n",
       " 'Semeion Handwritten Digit',\n",
       " 'SECOM',\n",
       " 'Plants',\n",
       " 'Libras Movement',\n",
       " 'Concrete Slump Test',\n",
       " 'Communities and Crime',\n",
       " 'Acute Inflammations',\n",
       " 'Wine Quality',\n",
       " 'URL Reputation',\n",
       " 'p53 Mutants',\n",
       " 'Parkinsons Telemonitoring',\n",
       " 'Demospongiae',\n",
       " 'Opinosis Opinion ⁄ Review',\n",
       " 'Breast Tissue',\n",
       " 'Cardiotocography',\n",
       " 'Wall-Following Robot Navigation Data',\n",
       " 'Spoken Arabic Digit',\n",
       " 'Localization Data for Person Activity',\n",
       " 'AutoUniv',\n",
       " 'Steel Plates Faults',\n",
       " 'MiniBooNE particle identification',\n",
       " 'YearPredictionMSD',\n",
       " 'PEMS-SF',\n",
       " 'OpinRank Review Dataset',\n",
       " 'Relative location of CT slices on axial axis',\n",
       " 'Online Handwritten Assamese Characters Dataset',\n",
       " 'PubChem Bioassay Data',\n",
       " 'Record Linkage Comparison Patterns',\n",
       " 'Communities and Crime Unnormalized',\n",
       " 'Vertebral Column',\n",
       " 'EMG Physical Action Data Set',\n",
       " 'Vicon Physical Action Data Set',\n",
       " 'Amazon Commerce reviews set',\n",
       " 'Amazon Access Samples',\n",
       " 'Reuter_50_50',\n",
       " 'Farm Ads',\n",
       " 'DBWorld e-mails',\n",
       " 'KEGG Metabolic Relation Network (Directed)',\n",
       " 'KEGG Metabolic Reaction Network (Undirected)',\n",
       " 'Bank Marketing',\n",
       " 'YouTube Comedy Slam Preference Data',\n",
       " 'Gas Sensor Array Drift Dataset',\n",
       " 'ILPD (Indian Liver Patient Dataset)',\n",
       " 'OPPORTUNITY Activity Recognition',\n",
       " 'Nomao',\n",
       " 'SMS Spam Collection',\n",
       " 'Skin Segmentation',\n",
       " 'Planning Relax',\n",
       " 'PAMAP2 Physical Activity Monitoring',\n",
       " 'Restaurant & consumer data',\n",
       " 'CNAE-9',\n",
       " 'Individual household electric power consumption',\n",
       " 'seeds',\n",
       " 'Northix',\n",
       " 'QtyT40I10D100K',\n",
       " 'Legal Case Reports',\n",
       " 'Human Activity Recognition Using Smartphones',\n",
       " 'One-hundred plant species leaves data set',\n",
       " 'Energy efficiency',\n",
       " 'Yacht Hydrodynamics',\n",
       " 'Fertility',\n",
       " 'Daphnet Freezing of Gait',\n",
       " '3D Road Network (North Jutland, Denmark)',\n",
       " 'ISTANBUL STOCK EXCHANGE',\n",
       " 'Buzz in social media',\n",
       " 'First-order theorem proving',\n",
       " 'Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)',\n",
       " 'Gas sensor arrays in open sampling settings',\n",
       " 'Climate Model Simulation Crashes',\n",
       " 'MicroMass',\n",
       " 'QSAR biodegradation',\n",
       " 'BLOGGER',\n",
       " 'Daily and Sports Activities',\n",
       " 'User Knowledge Modeling',\n",
       " 'Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection',\n",
       " 'NYSK',\n",
       " 'Turkiye Student Evaluation',\n",
       " \"ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines)\",\n",
       " 'EEG Eye State',\n",
       " 'Physicochemical Properties of Protein Tertiary Structure',\n",
       " 'seismic-bumps',\n",
       " 'banknote authentication',\n",
       " 'USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder Problem: Pat',\n",
       " 'YouTube Multiview Video Games Dataset',\n",
       " 'Gas Sensor Array Drift Dataset at Different Concentrations',\n",
       " 'Activities of Daily Living (ADLs) Recognition Using Binary Sensors',\n",
       " 'SkillCraft1 Master Table Dataset',\n",
       " 'Weight Lifting Exercises monitored with Inertial Measurement Units',\n",
       " 'SML2010',\n",
       " 'Bike Sharing Dataset',\n",
       " 'Predict keywords activities in a online social media',\n",
       " 'Thoracic Surgery Data',\n",
       " 'EMG dataset in Lower Limb',\n",
       " 'SUSY',\n",
       " 'HIGGS',\n",
       " 'Qualitative_Bankruptcy',\n",
       " 'LSVT Voice Rehabilitation',\n",
       " 'Dataset for ADL Recognition with Wrist-worn Accelerometer',\n",
       " 'Wilt',\n",
       " 'User Identification From Walking Activity',\n",
       " 'Activity Recognition from Single Chest-Mounted Accelerometer',\n",
       " 'Leaf',\n",
       " 'Dresses_Attribute_Sales',\n",
       " 'Tamilnadu Electricity Board Hourly Readings',\n",
       " 'Airfoil Self-Noise',\n",
       " 'Wholesale customers',\n",
       " 'Twitter Data set for Arabic Sentiment Analysis',\n",
       " 'Combined Cycle Power Plant',\n",
       " 'Urban Land Cover',\n",
       " 'Diabetes 130-US hospitals for years 1999-2008',\n",
       " 'Bach Choral Harmony',\n",
       " 'StoneFlakes',\n",
       " 'Tennis Major Tournament Match Statistics',\n",
       " 'Parkinson Speech Dataset with Multiple Types of Sound Recordings',\n",
       " 'Gesture Phase Segmentation',\n",
       " 'Perfume Data',\n",
       " 'BlogFeedback',\n",
       " 'REALDISP Activity Recognition Dataset',\n",
       " 'Newspaper and magazine images segmentation dataset',\n",
       " 'AAAI 2014 Accepted Papers',\n",
       " 'Gas sensor array under flow modulation',\n",
       " 'Gas sensor array exposed to turbulent gas mixtures',\n",
       " 'UJIIndoorLoc',\n",
       " 'Sentence Classification',\n",
       " 'Dow Jones Index',\n",
       " 'sEMG for Basic Hand movements',\n",
       " 'AAAI 2013 Accepted Papers',\n",
       " 'Geographical Original of Music',\n",
       " 'Condition Based Maintenance of Naval Propulsion Plants',\n",
       " 'Grammatical Facial Expressions',\n",
       " 'NoisyOffice',\n",
       " 'MHEALTH Dataset',\n",
       " 'Student Performance',\n",
       " 'ElectricityLoadDiagrams20112014',\n",
       " 'Gas sensor array under dynamic gas mixtures',\n",
       " 'microblogPCU',\n",
       " 'Firm-Teacher_Clave-Direction_Classification',\n",
       " 'Dataset for Sensorless Drive Diagnosis',\n",
       " 'TV News Channel Commercial Detection Dataset',\n",
       " 'Phishing Websites',\n",
       " 'Greenhouse Gas Observing Network',\n",
       " 'Diabetic Retinopathy Debrecen Data Set',\n",
       " 'HIV-1 protease cleavage',\n",
       " 'Sentiment Labelled Sentences',\n",
       " 'Online News Popularity',\n",
       " 'Forest type mapping',\n",
       " 'wiki4HE',\n",
       " 'Online Video Characteristics and Transcoding Time Dataset',\n",
       " 'Chronic_Kidney_Disease',\n",
       " 'Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014',\n",
       " 'Folio',\n",
       " 'Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015',\n",
       " 'Cuff-Less Blood Pressure Estimation',\n",
       " 'Smartphone-Based Recognition of Human Activities and Postural Transitions',\n",
       " 'Mice Protein Expression',\n",
       " 'UJIIndoorLoc-Mag',\n",
       " 'Heterogeneity Activity Recognition',\n",
       " 'Educational Process Mining (EPM): A Learning Analytics Data Set',\n",
       " 'HEPMASS',\n",
       " 'Indoor User Movement Prediction from RSS data',\n",
       " 'Open University Learning Analytics dataset',\n",
       " 'default of credit card clients',\n",
       " 'Mesothelioma’s disease data set',\n",
       " 'Online Retail',\n",
       " 'SIFT10M',\n",
       " 'GPS Trajectories',\n",
       " 'Detect Malacious Executable(AntiVirus)',\n",
       " 'Occupancy Detection',\n",
       " 'Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinson’s Disease',\n",
       " 'News Aggregator',\n",
       " 'Air Quality',\n",
       " 'Twin gas sensor arrays',\n",
       " 'Gas sensors for home activity monitoring',\n",
       " 'Facebook Comment Volume Dataset',\n",
       " 'Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL)',\n",
       " 'Polish companies bankruptcy data',\n",
       " 'Activity Recognition system based on Multisensor data fusion (AReM)',\n",
       " 'Dota2 Games Results',\n",
       " 'Facebook metrics',\n",
       " 'UbiqLog (smartphone lifelogging)',\n",
       " 'NIPS Conference Papers 1987-2015',\n",
       " 'HTRU2',\n",
       " 'Drug consumption (quantified)',\n",
       " 'Appliances energy prediction',\n",
       " 'Miskolc IIS Hybrid IPS',\n",
       " 'KDC-4007 dataset Collection',\n",
       " 'Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone',\n",
       " 'DrivFace',\n",
       " 'Website Phishing',\n",
       " 'YouTube Spam Collection',\n",
       " 'Beijing PM2.5 Data',\n",
       " 'Cargo 2000 Freight Tracking and Tracing',\n",
       " 'Cervical cancer (Risk Factors)',\n",
       " 'Quality Assessment of Digital Colposcopies',\n",
       " 'KASANDR',\n",
       " 'FMA: A Dataset For Music Analysis',\n",
       " 'Air quality',\n",
       " 'Epileptic Seizure Recognition',\n",
       " 'Devanagari Handwritten Character Dataset',\n",
       " 'Stock portfolio performance',\n",
       " 'MoCap Hand Postures',\n",
       " 'Early biomarkers of Parkinson�s disease based on natural connected speech',\n",
       " 'Data for Software Engineering Teamwork Assessment in Education Setting',\n",
       " 'PM2.5 Data of Five Chinese Cities',\n",
       " 'Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet',\n",
       " 'Sales_Transactions_Dataset_Weekly',\n",
       " 'Las Vegas Strip',\n",
       " 'Eco-hotel',\n",
       " 'MEU-Mobile KSD',\n",
       " 'Crowdsourced Mapping',\n",
       " 'gene expression cancer RNA-Seq',\n",
       " 'Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer',\n",
       " 'chestnut – LARVIC',\n",
       " 'Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network',\n",
       " 'Motion Capture Hand Postures',\n",
       " 'Anuran Calls (MFCCs)',\n",
       " 'TTC-3600: Benchmark dataset for Turkish text categorization',\n",
       " 'Gastrointestinal Lesions in Regular Colonoscopy',\n",
       " 'Daily Demand Forecasting Orders',\n",
       " 'Paper Reviews',\n",
       " 'extention of Z-Alizadeh sani dataset',\n",
       " 'Z-Alizadeh Sani',\n",
       " 'Dynamic Features of VirusShare Executables',\n",
       " 'IDA2016Challenge',\n",
       " 'DSRC Vehicle Communications',\n",
       " 'Mturk User-Perceived Clusters over Images',\n",
       " 'Character Font Images',\n",
       " 'DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels',\n",
       " 'Autistic Spectrum Disorder Screening Data for Children',\n",
       " 'Autistic Spectrum Disorder Screening Data for Adolescent',\n",
       " 'APS Failure at Scania Trucks',\n",
       " 'Wireless Indoor Localization',\n",
       " 'HCC Survival',\n",
       " 'CSM (Conventional and Social Media Movies) Dataset 2014 and 2015',\n",
       " 'University of Tehran Question Dataset 2016 (UTQD.2016)',\n",
       " 'Autism Screening Adult',\n",
       " 'Activity recognition with healthy older people using a batteryless wearable sensor',\n",
       " 'Immunotherapy Dataset',\n",
       " 'Cryotherapy Dataset',\n",
       " 'OCT data & Color Fundus Images of Left & Right Eyes',\n",
       " 'Discrete Tone Image Dataset',\n",
       " 'News Popularity in Multiple Social Media Platforms',\n",
       " 'Ultrasonic flowmeter diagnostics',\n",
       " 'ICMLA 2014 Accepted Papers Data Set',\n",
       " 'BLE RSSI Dataset for Indoor localization and Navigation',\n",
       " 'Container Crane Controller Data Set',\n",
       " 'Residential Building Data Set',\n",
       " 'Health News in Twitter',\n",
       " 'chipseq',\n",
       " 'SGEMM GPU kernel performance',\n",
       " 'Repeat Consumption Matrices',\n",
       " 'detection_of_IoT_botnet_attacks_N_BaIoT',\n",
       " 'Absenteeism at work',\n",
       " 'SCADI',\n",
       " 'Condition monitoring of hydraulic systems',\n",
       " 'Carbon Nanotubes',\n",
       " 'Optical Interconnection Network',\n",
       " 'Sports articles for objectivity analysis',\n",
       " 'Breast Cancer Coimbra',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data',\n",
       " 'Dishonest Internet users Dataset',\n",
       " 'Victorian Era Authorship Attribution',\n",
       " 'Simulated Falls and Daily Living Activities Data Set',\n",
       " 'Multimodal Damage Identification for Humanitarian Computing',\n",
       " 'EEG Steady-State Visual Evoked Potential Signals',\n",
       " 'Roman Urdu Data Set',\n",
       " 'Avila',\n",
       " 'PANDOR',\n",
       " 'Drug Review Dataset (Druglib.com)',\n",
       " 'Drug Review Dataset (Drugs.com)',\n",
       " 'Physical Unclonable Functions',\n",
       " 'Superconductivty Data',\n",
       " 'WESAD (Wearable Stress and Affect Detection)',\n",
       " 'GNFUV Unmanned Surface Vehicles Sensor Data Set 2',\n",
       " 'Student Academics Performance',\n",
       " 'Online Shoppers Purchasing Intention Dataset',\n",
       " 'PMU-UD',\n",
       " \"Parkinson's Disease Classification\",\n",
       " 'Electrical Grid Stability Simulated Data',\n",
       " 'Caesarian Section Classification Dataset',\n",
       " 'BAUM-1',\n",
       " 'BAUM-2',\n",
       " 'Audit Data',\n",
       " 'BuddyMove Data Set',\n",
       " 'Real estate valuation data set',\n",
       " 'Early biomarkers of Parkinson’s disease based on natural connected speech Data Set',\n",
       " 'Somerville Happiness Survey',\n",
       " '2.4 GHZ Indoor Channel Measurements',\n",
       " 'EMG data for gestures',\n",
       " 'Parking Birmingham',\n",
       " 'Behavior of the urban traffic of the city of Sao Paulo in Brazil',\n",
       " 'Travel Reviews',\n",
       " 'Tarvel Review Ratings',\n",
       " 'Rice Leaf Diseases',\n",
       " 'Gas sensor array temperature modulation',\n",
       " 'Facebook Live Sellers in Thailand',\n",
       " 'Parkinson Dataset with replicated acoustic features',\n",
       " 'Metro Interstate Traffic Volume',\n",
       " 'Query Analytics Workloads Dataset',\n",
       " 'Wave Energy Converters',\n",
       " 'PPG-DaLiA',\n",
       " 'Alcohol QCM Sensor Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " 'Incident management process enriched event log',\n",
       " 'Opinion Corpus for Lebanese Arabic Reviews (OCLAR)',\n",
       " 'MEx',\n",
       " 'Beijing Multi-Site Air-Quality Data',\n",
       " 'Online Retail II',\n",
       " 'Hepatitis C Virus (HCV) for Egyptian patients',\n",
       " 'QSAR fish toxicity',\n",
       " 'QSAR aquatic toxicity',\n",
       " 'Human Activity Recognition from Continuous Ambient Sensor Data',\n",
       " 'WISDM Smartphone and Smartwatch Activity and Biometrics Dataset',\n",
       " 'QSAR oral toxicity',\n",
       " 'QSAR androgen receptor',\n",
       " 'QSAR Bioconcentration classes dataset',\n",
       " 'QSAR fish bioconcentration factor (BCF)',\n",
       " 'A study of Asian Religious and Biblical Texts',\n",
       " 'Real-time Election Results: Portugal 2019',\n",
       " 'Bias correction of numerical prediction model temperature forecast',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Kitsune Network Attack Dataset',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'Speaker Accent Recognition',\n",
       " 'Heart failure clinical records',\n",
       " 'Deepfakes: Medical Image Tamper Detection',\n",
       " 'selfBACK',\n",
       " 'South German Credit',\n",
       " 'Exasens',\n",
       " 'Swarm Behaviour',\n",
       " 'Crop mapping using fused optical-radar data set',\n",
       " 'BitcoinHeistRansomwareAddressDataset',\n",
       " 'Facebook Large Page-Page Network',\n",
       " 'Amphibians',\n",
       " 'Early stage diabetes risk prediction dataset.',\n",
       " 'Turkish Spam V01',\n",
       " 'Stock keeping units',\n",
       " 'Demand Forecasting for a store',\n",
       " 'Detect Malware Types',\n",
       " 'Wave Energy Converters',\n",
       " 'Youtube cookery channels viewers comments in Hinglish',\n",
       " 'Pedestrian in Traffic Dataset',\n",
       " 'Cervical Cancer Behavior Risk',\n",
       " 'Sattriya_Dance_Single_Hand_Gestures Dataset',\n",
       " 'Divorce Predictors data set',\n",
       " '3W dataset',\n",
       " 'Malware static and dynamic features VxHeaven and Virus Total',\n",
       " 'Internet Firewall Data',\n",
       " 'User Profiling and Abusive Language Detection Dataset',\n",
       " 'Estimation of obesity levels based on eating habits and physical condition',\n",
       " 'Rice (Cammeo and Osmancik)',\n",
       " 'Vehicle routing and scheduling problems',\n",
       " 'Algerian Forest Fires Dataset',\n",
       " 'Breath Metabolomics',\n",
       " 'Horton General Hospital',\n",
       " 'UrbanGB, urban road accidents coordinates labelled by the urban center',\n",
       " 'Gas Turbine CO and NOx Emission Data Set',\n",
       " 'Activity recognition using wearable physiological measurements',\n",
       " 'clickstream data for online shopping',\n",
       " 'CNNpred: CNN-based stock market prediction using a diverse set of variables',\n",
       " 'Apartment for rent classified',\n",
       " ': Simulated Data set of Iraqi tourism places',\n",
       " 'Nasarian CAD Dataset',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Bar Crawl: Detecting Heavy Drinking',\n",
       " 'Seoul Bike Sharing Demand',\n",
       " 'Person Classification Gait Data',\n",
       " 'Shill Bidding Dataset',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Bone marrow transplant: children',\n",
       " 'Exasens',\n",
       " 'COVID-19 Surveillance',\n",
       " 'Refractive errors',\n",
       " 'Shoulder Implant X-Ray Manufacturer Classification',\n",
       " 'CLINC150',\n",
       " 'HCV data',\n",
       " 'Taiwanese Bankruptcy Prediction',\n",
       " 'South German Credit (UPDATE)',\n",
       " 'IIWA14-R820-Gazebo-Dataset-10Trajectories',\n",
       " 'Guitar Chords finger positions',\n",
       " 'Russian Corpus of Biographical Texts',\n",
       " 'Codon usage',\n",
       " 'Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset',\n",
       " 'Myocardial infarction complications',\n",
       " 'Hungarian Chickenpox Cases',\n",
       " 'Simulated data for survival modelling',\n",
       " 'Student Performance on an entrance examination',\n",
       " 'Chemical Composition of Ceramic Samples',\n",
       " 'Labeled Text Forum Threads Dataset',\n",
       " 'Stock keeping units',\n",
       " 'BLE RSSI dataset for Indoor localization',\n",
       " 'Basketball dataset',\n",
       " 'GitHub MUSAE',\n",
       " 'Anticancer peptides',\n",
       " 'Monolithic Columns in Troad and Mysia Region',\n",
       " 'Gender by Name',\n",
       " 'Iranian Churn Dataset',\n",
       " 'Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " 'Shoulder Implant Manufacture Classification',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wheat kernels',\n",
       " 'Productivity Prediction of Garment Employees',\n",
       " 'Multi-view Brain Networks',\n",
       " 'LastFM Asia Social Network',\n",
       " 'Wisesight Sentiment Corpus',\n",
       " 'AI4I 2020 Predictive Maintenance Dataset',\n",
       " 'Dry Bean Dataset',\n",
       " 'in-vehicle coupon recommendation',\n",
       " 'Gait Classification',\n",
       " 'Wikipedia Math Essentials',\n",
       " 'Wikipedia Math Essentials',\n",
       " 'Synchronous Machine Data Set',\n",
       " 'Average Localization Error (ALE) in sensor node localization process in WSNs',\n",
       " '9mers from cullpdb',\n",
       " 'TamilSentiMix',\n",
       " 'Accelerometer',\n",
       " 'Synchronous Machine Data Set',\n",
       " 'Pedal Me Bicycle Deliveries',\n",
       " 'Turkish Headlines Dataset',\n",
       " 'Secondary Mushroom Dataset',\n",
       " 'Power consumption of Tetouan city',\n",
       " 'Raisin Dataset',\n",
       " 'Steel Industry Energy Consumption Dataset',\n",
       " 'Gender Gap in Spanish WP',\n",
       " 'Non verbal tourists data',\n",
       " 'Roman Urdu Sentiment Analysis Dataset (RUSAD)',\n",
       " 'TUANDROMD ( Tezpur University Android Malware Dataset)',\n",
       " 'Higher Education Students Performance Evaluation Dataset',\n",
       " 'Risk Factor prediction of Chronic Kidney Disease',\n",
       " 'Lab Test',\n",
       " 'Shoulder Implant Manufacture Classification',\n",
       " 'Rocket League Skillshots Data Set',\n",
       " 'Sepsis survival minimal clinical records',\n",
       " 'Water Quality Prediction',\n",
       " 'Traffic Flow Forecasting',\n",
       " 'sentiment analysis in Saudi Arabia about distance education during Covid-19',\n",
       " 'Kain Tradisional Sambas',\n",
       " 'Image Recognition Task Execution Times in Mobile Edge Computing',\n",
       " 'REWEMA',\n",
       " 'REJAFADA',\n",
       " 'Steel Industry Energy Consumption Dataset',\n",
       " 'Influenza outbreak event prediction via Twitter data',\n",
       " 'Turkish Music Emotion Dataset',\n",
       " 'Maternal Health Risk Data Set',\n",
       " 'Room Occupancy Estimation',\n",
       " 'Image Recognition Task Execution Times in Mobile Edge Computing']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataSet_Name=[]\n",
    "data=driver.find_elements(By.XPATH,\"//p[@class='normal']/b/a\")\n",
    "for i in data:\n",
    "    DataSet_Name.append(i.text)\n",
    "    \n",
    "DataSet_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "afebd9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DataSet_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "16f9cdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Recommender-Systems ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Function-Learning ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Relational-Learning ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Recommender-Systems ',\n",
       " 'Classification ',\n",
       " 'Regression, Description ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Causal-Discovery ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering, Causal-Discovery ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression, Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering, Causa ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering, Causal-Discovery ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering, Causal-Discovery ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Clustering, Causal-Discovery ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Causal-Discovery ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Causal-Discovery ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering, Causal-Discovery ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Causal-Discovery ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Recommendation ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression, Clustering ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering, Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Causal-Discovery ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Causal-Discovery ',\n",
       " 'Clustering ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Task=[]\n",
    "task=driver.find_elements(By.XPATH,\"//td[3]/p[@class='normal']\")\n",
    "for i in task[0:622]:\n",
    "    Task.append(i.text)\n",
    "    \n",
    "Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7e75d0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "594162d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Categorical, Integer, Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " ' ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Real, Integer ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer, Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical, Real ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " 'Categorical, Real ',\n",
       " ' ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Categorical ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attribute_type=[]\n",
    "\n",
    "types=driver.find_elements(By.XPATH,\"//td[4]/p[@class='normal']\")\n",
    "for i in types:\n",
    "    \n",
    "    Attribute_type.append(i.text)\n",
    "        \n",
    "Attribute_type\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fd3595c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4177 ',\n",
       " '48842 ',\n",
       " '798 ',\n",
       " '37711 ',\n",
       " '452 ',\n",
       " '6000 ',\n",
       " '226 ',\n",
       " '226 ',\n",
       " '398 ',\n",
       " '205 ',\n",
       " '294 ',\n",
       " '625 ',\n",
       " '16 ',\n",
       " '286 ',\n",
       " '699 ',\n",
       " '198 ',\n",
       " '569 ',\n",
       " '108 ',\n",
       " '1728 ',\n",
       " '48842 ',\n",
       " ' ',\n",
       " '3196 ',\n",
       " '28056 ',\n",
       " ' ',\n",
       " '100 ',\n",
       " '67557 ',\n",
       " '690 ',\n",
       " '125 ',\n",
       " '209 ',\n",
       " '1473 ',\n",
       " '581012 ',\n",
       " '512 ',\n",
       " '366 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '132 ',\n",
       " '336 ',\n",
       " '194 ',\n",
       " '352 ',\n",
       " '214 ',\n",
       " '306 ',\n",
       " '160 ',\n",
       " '303 ',\n",
       " '155 ',\n",
       " '368 ',\n",
       " ' ',\n",
       " '2310 ',\n",
       " '3279 ',\n",
       " '351 ',\n",
       " '150 ',\n",
       " '7797 ',\n",
       " '104 ',\n",
       " '57 ',\n",
       " ' ',\n",
       " '24 ',\n",
       " '20000 ',\n",
       " '345 ',\n",
       " ' ',\n",
       " '32 ',\n",
       " '148 ',\n",
       " '209 ',\n",
       " '528 ',\n",
       " ' ',\n",
       " '106 ',\n",
       " '128 ',\n",
       " '3190 ',\n",
       " '432 ',\n",
       " '202 ',\n",
       " '2000 ',\n",
       " '8124 ',\n",
       " '476 ',\n",
       " '6598 ',\n",
       " '12960 ',\n",
       " ' ',\n",
       " '5473 ',\n",
       " '5620 ',\n",
       " '10992 ',\n",
       " '90 ',\n",
       " '339 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '167 ',\n",
       " '15 ',\n",
       " '1389 ',\n",
       " '307 ',\n",
       " '47 ',\n",
       " '23 ',\n",
       " '531 ',\n",
       " '4601 ',\n",
       " '267 ',\n",
       " '267 ',\n",
       " '76 ',\n",
       " ' ',\n",
       " '1000 ',\n",
       " '151 ',\n",
       " '958 ',\n",
       " '7200 ',\n",
       " '10 ',\n",
       " '285 ',\n",
       " '435 ',\n",
       " '527 ',\n",
       " '5000 ',\n",
       " '5000 ',\n",
       " '178 ',\n",
       " '1484 ',\n",
       " '101 ',\n",
       " ' ',\n",
       " '20000 ',\n",
       " '6650 ',\n",
       " '2565 ',\n",
       " '2458285 ',\n",
       " '299285 ',\n",
       " '340 ',\n",
       " '68040 ',\n",
       " ' ',\n",
       " '122 ',\n",
       " '178080 ',\n",
       " '50672 ',\n",
       " '640 ',\n",
       " '9000 ',\n",
       " '10104 ',\n",
       " '256932 ',\n",
       " '640 ',\n",
       " '191779 ',\n",
       " '4000000 ',\n",
       " ' ',\n",
       " '10000 ',\n",
       " '989818 ',\n",
       " '129000 ',\n",
       " ' ',\n",
       " '100000 ',\n",
       " '21578 ',\n",
       " '463 ',\n",
       " '600 ',\n",
       " '332 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '690 ',\n",
       " '1000 ',\n",
       " '270 ',\n",
       " '6435 ',\n",
       " '2310 ',\n",
       " '58000 ',\n",
       " '946 ',\n",
       " '20008 ',\n",
       " '208 ',\n",
       " '528 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1024 ',\n",
       " '10080 ',\n",
       " '50400 ',\n",
       " '1025010 ',\n",
       " '19020 ',\n",
       " '1364 ',\n",
       " '961 ',\n",
       " '517 ',\n",
       " '200 ',\n",
       " '8000000 ',\n",
       " '1030 ',\n",
       " '606 ',\n",
       " '900 ',\n",
       " '2600 ',\n",
       " '1950 ',\n",
       " '13500 ',\n",
       " '4400 ',\n",
       " '2536 ',\n",
       " '300 ',\n",
       " '197 ',\n",
       " '2858 ',\n",
       " '748 ',\n",
       " '11640 ',\n",
       " '1593 ',\n",
       " '1567 ',\n",
       " '22632 ',\n",
       " '360 ',\n",
       " '103 ',\n",
       " '1994 ',\n",
       " '120 ',\n",
       " '4898 ',\n",
       " '2396130 ',\n",
       " '16772 ',\n",
       " '5875 ',\n",
       " '503 ',\n",
       " '51 ',\n",
       " '106 ',\n",
       " '2126 ',\n",
       " '5456 ',\n",
       " '8800 ',\n",
       " '164860 ',\n",
       " ' ',\n",
       " '1941 ',\n",
       " '130065 ',\n",
       " '515345 ',\n",
       " '440 ',\n",
       " ' ',\n",
       " '53500 ',\n",
       " '8235 ',\n",
       " ' ',\n",
       " '5749132 ',\n",
       " '2215 ',\n",
       " '310 ',\n",
       " '10000 ',\n",
       " '3000 ',\n",
       " '1500 ',\n",
       " '30000 ',\n",
       " '2500 ',\n",
       " '4143 ',\n",
       " '64 ',\n",
       " '53414 ',\n",
       " '65554 ',\n",
       " '45211 ',\n",
       " '1138562 ',\n",
       " '13910 ',\n",
       " '583 ',\n",
       " '2551 ',\n",
       " '34465 ',\n",
       " '5574 ',\n",
       " '245057 ',\n",
       " '182 ',\n",
       " '3850505 ',\n",
       " '138 ',\n",
       " '1080 ',\n",
       " '2075259 ',\n",
       " '210 ',\n",
       " '115 ',\n",
       " '3960456 ',\n",
       " ' ',\n",
       " '10299 ',\n",
       " '1600 ',\n",
       " '768 ',\n",
       " '308 ',\n",
       " '100 ',\n",
       " '237 ',\n",
       " '434874 ',\n",
       " '536 ',\n",
       " '140000 ',\n",
       " '6118 ',\n",
       " '165632 ',\n",
       " '18000 ',\n",
       " '540 ',\n",
       " '931 ',\n",
       " '1055 ',\n",
       " '100 ',\n",
       " '9120 ',\n",
       " '403 ',\n",
       " '111740 ',\n",
       " '10421 ',\n",
       " '5820 ',\n",
       " '403 ',\n",
       " '14980 ',\n",
       " '45730 ',\n",
       " '2584 ',\n",
       " '1372 ',\n",
       " '306 ',\n",
       " '120000 ',\n",
       " '13910 ',\n",
       " '2747 ',\n",
       " '3395 ',\n",
       " '39242 ',\n",
       " '4137 ',\n",
       " '17389 ',\n",
       " '51 ',\n",
       " '470 ',\n",
       " '132 ',\n",
       " '5000000 ',\n",
       " '11000000 ',\n",
       " '250 ',\n",
       " '126 ',\n",
       " ' ',\n",
       " '4889 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '340 ',\n",
       " '501 ',\n",
       " '45781 ',\n",
       " '1503 ',\n",
       " '440 ',\n",
       " '2000 ',\n",
       " '9568 ',\n",
       " '168 ',\n",
       " '100000 ',\n",
       " '5665 ',\n",
       " '79 ',\n",
       " '127 ',\n",
       " '1040 ',\n",
       " '9900 ',\n",
       " '560 ',\n",
       " '60021 ',\n",
       " '1419 ',\n",
       " '101 ',\n",
       " '399 ',\n",
       " '58 ',\n",
       " '180 ',\n",
       " '21048 ',\n",
       " ' ',\n",
       " '750 ',\n",
       " '3000 ',\n",
       " '150 ',\n",
       " '1059 ',\n",
       " '11934 ',\n",
       " '27965 ',\n",
       " '216 ',\n",
       " '120 ',\n",
       " '649 ',\n",
       " '370 ',\n",
       " '4178504 ',\n",
       " '221579 ',\n",
       " '10800 ',\n",
       " '58509 ',\n",
       " '129685 ',\n",
       " '2456 ',\n",
       " '2921 ',\n",
       " '1151 ',\n",
       " '6590 ',\n",
       " '3000 ',\n",
       " '39797 ',\n",
       " '326 ',\n",
       " '913 ',\n",
       " '168286 ',\n",
       " '400 ',\n",
       " '314080 ',\n",
       " '637 ',\n",
       " '1710671 ',\n",
       " '12000 ',\n",
       " '10929 ',\n",
       " '1080 ',\n",
       " '40000 ',\n",
       " '43930257 ',\n",
       " '230318 ',\n",
       " '10500000 ',\n",
       " '13197 ',\n",
       " ' ',\n",
       " '30000 ',\n",
       " '324 ',\n",
       " '541909 ',\n",
       " '11164866 ',\n",
       " '163 ',\n",
       " '373 ',\n",
       " '20560 ',\n",
       " '40 ',\n",
       " '422937 ',\n",
       " '9358 ',\n",
       " '640 ',\n",
       " '919438 ',\n",
       " '40949 ',\n",
       " '5744 ',\n",
       " '10503 ',\n",
       " '42240 ',\n",
       " '102944 ',\n",
       " '500 ',\n",
       " '9782222 ',\n",
       " '11463 ',\n",
       " '17898 ',\n",
       " '1885 ',\n",
       " '19735 ',\n",
       " '1540 ',\n",
       " '4007 ',\n",
       " '153540 ',\n",
       " '606 ',\n",
       " '1353 ',\n",
       " '1956 ',\n",
       " '43824 ',\n",
       " '3942 ',\n",
       " '858 ',\n",
       " '287 ',\n",
       " '17764280 ',\n",
       " '106574 ',\n",
       " '9358 ',\n",
       " '11500 ',\n",
       " '92000 ',\n",
       " '315 ',\n",
       " '78095 ',\n",
       " '130 ',\n",
       " '74 ',\n",
       " '52854 ',\n",
       " '77 ',\n",
       " '811 ',\n",
       " '504 ',\n",
       " '401 ',\n",
       " '2856 ',\n",
       " '10546 ',\n",
       " '801 ',\n",
       " '1540 ',\n",
       " '1451 ',\n",
       " '1075 ',\n",
       " '78095 ',\n",
       " '7195 ',\n",
       " '3600 ',\n",
       " '76 ',\n",
       " '60 ',\n",
       " '405 ',\n",
       " '303 ',\n",
       " '303 ',\n",
       " '107888 ',\n",
       " '76000 ',\n",
       " '10000 ',\n",
       " '180 ',\n",
       " '745000 ',\n",
       " '12234 ',\n",
       " '292 ',\n",
       " '104 ',\n",
       " '60000 ',\n",
       " '2000 ',\n",
       " '165 ',\n",
       " '217 ',\n",
       " '1175 ',\n",
       " '704 ',\n",
       " '75128 ',\n",
       " '90 ',\n",
       " '90 ',\n",
       " '50 ',\n",
       " '71 ',\n",
       " '93239 ',\n",
       " '540 ',\n",
       " '105 ',\n",
       " '6611 ',\n",
       " '15 ',\n",
       " '372 ',\n",
       " '58000 ',\n",
       " '4960 ',\n",
       " '241600 ',\n",
       " '130000 ',\n",
       " '7062606 ',\n",
       " '740 ',\n",
       " '70 ',\n",
       " '2205 ',\n",
       " '10721 ',\n",
       " '640 ',\n",
       " '1000 ',\n",
       " '116 ',\n",
       " '1672 ',\n",
       " '322 ',\n",
       " '93600 ',\n",
       " '3060 ',\n",
       " '5879 ',\n",
       " '9200 ',\n",
       " '20000 ',\n",
       " '20867 ',\n",
       " ' ',\n",
       " '4143 ',\n",
       " '215063 ',\n",
       " '6000000 ',\n",
       " '21263 ',\n",
       " '63000000 ',\n",
       " '10190 ',\n",
       " '300 ',\n",
       " '12330 ',\n",
       " '5180 ',\n",
       " '756 ',\n",
       " '10000 ',\n",
       " '80 ',\n",
       " '1184 ',\n",
       " '1047 ',\n",
       " '777 ',\n",
       " '249 ',\n",
       " '414 ',\n",
       " ' ',\n",
       " '143 ',\n",
       " '7840 ',\n",
       " '30000 ',\n",
       " '35717 ',\n",
       " '135 ',\n",
       " '980 ',\n",
       " '5456 ',\n",
       " '120 ',\n",
       " '4095000 ',\n",
       " '7051 ',\n",
       " '240 ',\n",
       " '48204 ',\n",
       " '260000 ',\n",
       " '288000 ',\n",
       " '8300000 ',\n",
       " '125 ',\n",
       " '170 ',\n",
       " '141712 ',\n",
       " '3916 ',\n",
       " '6262 ',\n",
       " '420768 ',\n",
       " '1067371 ',\n",
       " '1385 ',\n",
       " '908 ',\n",
       " '546 ',\n",
       " '13956534 ',\n",
       " '15630426 ',\n",
       " '8992 ',\n",
       " '1687 ',\n",
       " '779 ',\n",
       " '1056 ',\n",
       " '590 ',\n",
       " '21643 ',\n",
       " '7750 ',\n",
       " '14057567 ',\n",
       " '27170754 ',\n",
       " '597 ',\n",
       " '329 ',\n",
       " '299 ',\n",
       " '20000 ',\n",
       " '26136 ',\n",
       " '1000 ',\n",
       " '399 ',\n",
       " '24017 ',\n",
       " '325834 ',\n",
       " '2916697 ',\n",
       " '22470 ',\n",
       " '189 ',\n",
       " '520 ',\n",
       " '826 ',\n",
       " '2279 ',\n",
       " '28764 ',\n",
       " '7107 ',\n",
       " '288000 ',\n",
       " '9800 ',\n",
       " '4760 ',\n",
       " '72 ',\n",
       " '1450 ',\n",
       " '170 ',\n",
       " '1984 ',\n",
       " '2955 ',\n",
       " '65532 ',\n",
       " '65919 ',\n",
       " '2111 ',\n",
       " '3810 ',\n",
       " '18 ',\n",
       " '244 ',\n",
       " '104 ',\n",
       " '139 ',\n",
       " '360177 ',\n",
       " '36733 ',\n",
       " '4480 ',\n",
       " '165474 ',\n",
       " '1985 ',\n",
       " '10000 ',\n",
       " '232 ',\n",
       " '150 ',\n",
       " '11 ',\n",
       " '14057567 ',\n",
       " '8760 ',\n",
       " '48 ',\n",
       " '6321 ',\n",
       " '3150 ',\n",
       " '17256 ',\n",
       " '187 ',\n",
       " '399 ',\n",
       " '14 ',\n",
       " '467 ',\n",
       " '597 ',\n",
       " '23700 ',\n",
       " '615 ',\n",
       " '6819 ',\n",
       " '1000 ',\n",
       " ' ',\n",
       " '2633 ',\n",
       " '200 ',\n",
       " '13028 ',\n",
       " '800 ',\n",
       " '1700 ',\n",
       " '521 ',\n",
       " '120000 ',\n",
       " '666 ',\n",
       " '88 ',\n",
       " '200 ',\n",
       " '2279 ',\n",
       " '23570 ',\n",
       " '10000 ',\n",
       " '37700 ',\n",
       " '1850 ',\n",
       " '11 ',\n",
       " '147270 ',\n",
       " '3150 ',\n",
       " '17256 ',\n",
       " '597 ',\n",
       " '7624 ',\n",
       " '314 ',\n",
       " '1197 ',\n",
       " '70 ',\n",
       " '7624 ',\n",
       " '26737 ',\n",
       " '10000 ',\n",
       " '13611 ',\n",
       " '12684 ',\n",
       " '48 ',\n",
       " '731 ',\n",
       " '731 ',\n",
       " '557 ',\n",
       " '107 ',\n",
       " '158716 ',\n",
       " '15744 ',\n",
       " '153000 ',\n",
       " '557 ',\n",
       " '36 ',\n",
       " '4200 ',\n",
       " '61069 ',\n",
       " '52417 ',\n",
       " '900 ',\n",
       " '35040 ',\n",
       " '4746 ',\n",
       " '73 ',\n",
       " '11000 ',\n",
       " '4465 ',\n",
       " '145 ',\n",
       " '202 ',\n",
       " '221 ',\n",
       " '597 ',\n",
       " '298 ',\n",
       " '110341 ',\n",
       " '705 ',\n",
       " '2101 ',\n",
       " '1765 ',\n",
       " '150 ',\n",
       " '4000 ',\n",
       " '6272 ',\n",
       " '1996 ',\n",
       " '35040 ',\n",
       " '75840 ',\n",
       " '400 ',\n",
       " '1014 ',\n",
       " '10129 ',\n",
       " '4000 ']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Instances=[]\n",
    "instance=driver.find_elements(By.XPATH,\"//td[5]/p[@class='normal']\")\n",
    "for i in instance:\n",
    "    Instances.append(i.text)\n",
    "Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e9dd74ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8 ',\n",
       " '14 ',\n",
       " '38 ',\n",
       " '294 ',\n",
       " '279 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '69 ',\n",
       " '8 ',\n",
       " '26 ',\n",
       " '1 ',\n",
       " '4 ',\n",
       " '4 ',\n",
       " '9 ',\n",
       " '10 ',\n",
       " '34 ',\n",
       " '32 ',\n",
       " '13 ',\n",
       " '6 ',\n",
       " '14 ',\n",
       " '22 ',\n",
       " '36 ',\n",
       " '6 ',\n",
       " ' ',\n",
       " '6 ',\n",
       " '42 ',\n",
       " '15 ',\n",
       " ' ',\n",
       " '9 ',\n",
       " '9 ',\n",
       " '54 ',\n",
       " '39 ',\n",
       " '33 ',\n",
       " '20 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '12 ',\n",
       " '8 ',\n",
       " '30 ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '3 ',\n",
       " '5 ',\n",
       " '75 ',\n",
       " '19 ',\n",
       " '27 ',\n",
       " ' ',\n",
       " '19 ',\n",
       " '1558 ',\n",
       " '34 ',\n",
       " '4 ',\n",
       " '617 ',\n",
       " '12 ',\n",
       " '16 ',\n",
       " '7 ',\n",
       " '4 ',\n",
       " '16 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '56 ',\n",
       " '18 ',\n",
       " '8 ',\n",
       " '22 ',\n",
       " ' ',\n",
       " '58 ',\n",
       " ' ',\n",
       " '61 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '649 ',\n",
       " '22 ',\n",
       " '168 ',\n",
       " '168 ',\n",
       " '8 ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '64 ',\n",
       " '16 ',\n",
       " '8 ',\n",
       " '17 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '72 ',\n",
       " '4 ',\n",
       " '6 ',\n",
       " '10 ',\n",
       " '35 ',\n",
       " '35 ',\n",
       " '4 ',\n",
       " '102 ',\n",
       " '57 ',\n",
       " '22 ',\n",
       " '44 ',\n",
       " '45 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '9 ',\n",
       " '21 ',\n",
       " '32 ',\n",
       " '17 ',\n",
       " '16 ',\n",
       " '38 ',\n",
       " '21 ',\n",
       " '40 ',\n",
       " '13 ',\n",
       " '8 ',\n",
       " '17 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '15 ',\n",
       " '22 ',\n",
       " '68 ',\n",
       " '40 ',\n",
       " '17 ',\n",
       " '89 ',\n",
       " ' ',\n",
       " '4 ',\n",
       " '12 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '86 ',\n",
       " '72 ',\n",
       " '61 ',\n",
       " '12 ',\n",
       " '481 ',\n",
       " '42 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '90 ',\n",
       " ' ',\n",
       " '5 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '14 ',\n",
       " '20 ',\n",
       " '13 ',\n",
       " '36 ',\n",
       " '19 ',\n",
       " '9 ',\n",
       " '18 ',\n",
       " '4 ',\n",
       " '60 ',\n",
       " '10 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '4 ',\n",
       " '3 ',\n",
       " '11 ',\n",
       " '11 ',\n",
       " ' ',\n",
       " '6 ',\n",
       " '13 ',\n",
       " ' ',\n",
       " '100000 ',\n",
       " '9 ',\n",
       " '101 ',\n",
       " '10000 ',\n",
       " '20000 ',\n",
       " '100000 ',\n",
       " '5000 ',\n",
       " '500 ',\n",
       " '73 ',\n",
       " '43 ',\n",
       " '23 ',\n",
       " '3 ',\n",
       " '5 ',\n",
       " ' ',\n",
       " '256 ',\n",
       " '591 ',\n",
       " '70 ',\n",
       " '91 ',\n",
       " '10 ',\n",
       " '128 ',\n",
       " '6 ',\n",
       " '12 ',\n",
       " '3231961 ',\n",
       " '5409 ',\n",
       " '26 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '23 ',\n",
       " '24 ',\n",
       " '13 ',\n",
       " '8 ',\n",
       " ' ',\n",
       " '27 ',\n",
       " '50 ',\n",
       " '90 ',\n",
       " '138672 ',\n",
       " ' ',\n",
       " '386 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '12 ',\n",
       " '147 ',\n",
       " '6 ',\n",
       " '8 ',\n",
       " '27 ',\n",
       " '10000 ',\n",
       " '20000 ',\n",
       " '10000 ',\n",
       " '54877 ',\n",
       " '4702 ',\n",
       " '24 ',\n",
       " '29 ',\n",
       " '17 ',\n",
       " '3 ',\n",
       " '128 ',\n",
       " '10 ',\n",
       " '242 ',\n",
       " '120 ',\n",
       " ' ',\n",
       " '4 ',\n",
       " '13 ',\n",
       " '52 ',\n",
       " '47 ',\n",
       " '857 ',\n",
       " '9 ',\n",
       " '7 ',\n",
       " '200 ',\n",
       " '4 ',\n",
       " ' ',\n",
       " '561 ',\n",
       " '64 ',\n",
       " '8 ',\n",
       " '7 ',\n",
       " '10 ',\n",
       " '9 ',\n",
       " '4 ',\n",
       " '8 ',\n",
       " '77 ',\n",
       " '51 ',\n",
       " '18 ',\n",
       " '1950000 ',\n",
       " '18 ',\n",
       " '1300 ',\n",
       " '41 ',\n",
       " '6 ',\n",
       " '5625 ',\n",
       " '5 ',\n",
       " ' ',\n",
       " '7 ',\n",
       " '33 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '9 ',\n",
       " '19 ',\n",
       " '5 ',\n",
       " '5 ',\n",
       " '1000000 ',\n",
       " '129 ',\n",
       " ' ',\n",
       " '20 ',\n",
       " '152 ',\n",
       " '24 ',\n",
       " '16 ',\n",
       " '35 ',\n",
       " '17 ',\n",
       " '5 ',\n",
       " '18 ',\n",
       " '28 ',\n",
       " '7 ',\n",
       " '309 ',\n",
       " '3 ',\n",
       " '6 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '16 ',\n",
       " '13 ',\n",
       " '5 ',\n",
       " '6 ',\n",
       " '8 ',\n",
       " '2 ',\n",
       " '4 ',\n",
       " '148 ',\n",
       " '55 ',\n",
       " '17 ',\n",
       " '8 ',\n",
       " '42 ',\n",
       " '26 ',\n",
       " '50 ',\n",
       " '2 ',\n",
       " '281 ',\n",
       " '120 ',\n",
       " ' ',\n",
       " '6 ',\n",
       " '120432 ',\n",
       " '150000 ',\n",
       " '529 ',\n",
       " ' ',\n",
       " '16 ',\n",
       " '2500 ',\n",
       " '5 ',\n",
       " '68 ',\n",
       " '16 ',\n",
       " '100 ',\n",
       " '216 ',\n",
       " '23 ',\n",
       " '33 ',\n",
       " '140256 ',\n",
       " '19 ',\n",
       " '20 ',\n",
       " '20 ',\n",
       " '49 ',\n",
       " '12 ',\n",
       " '30 ',\n",
       " '5232 ',\n",
       " '20 ',\n",
       " '1 ',\n",
       " ' ',\n",
       " '61 ',\n",
       " '27 ',\n",
       " '53 ',\n",
       " '11 ',\n",
       " '25 ',\n",
       " '0 ',\n",
       " '20 ',\n",
       " '9 ',\n",
       " '3 ',\n",
       " '561 ',\n",
       " '82 ',\n",
       " '13 ',\n",
       " '16 ',\n",
       " '13 ',\n",
       " '28 ',\n",
       " '4 ',\n",
       " ' ',\n",
       " '24 ',\n",
       " '34 ',\n",
       " '8 ',\n",
       " '128 ',\n",
       " '15 ',\n",
       " '513 ',\n",
       " '7 ',\n",
       " '7 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '480000 ',\n",
       " '11 ',\n",
       " '54 ',\n",
       " '561 ',\n",
       " '64 ',\n",
       " '6 ',\n",
       " '116 ',\n",
       " '19 ',\n",
       " ' ',\n",
       " '5812 ',\n",
       " '9 ',\n",
       " '32 ',\n",
       " '29 ',\n",
       " '67 ',\n",
       " ' ',\n",
       " '25 ',\n",
       " '6400 ',\n",
       " '10 ',\n",
       " '5 ',\n",
       " '13 ',\n",
       " '98 ',\n",
       " '36 ',\n",
       " '69 ',\n",
       " '2158859 ',\n",
       " '518 ',\n",
       " '15 ',\n",
       " '179 ',\n",
       " ' ',\n",
       " '12 ',\n",
       " '38 ',\n",
       " '65 ',\n",
       " '102 ',\n",
       " '86 ',\n",
       " '7 ',\n",
       " '53 ',\n",
       " '20 ',\n",
       " '1 ',\n",
       " '71 ',\n",
       " '29 ',\n",
       " '20531 ',\n",
       " '65 ',\n",
       " '3 ',\n",
       " '22 ',\n",
       " '38 ',\n",
       " '22 ',\n",
       " '4814 ',\n",
       " '698 ',\n",
       " '13 ',\n",
       " '10 ',\n",
       " '59 ',\n",
       " '56 ',\n",
       " '482 ',\n",
       " '171 ',\n",
       " '5 ',\n",
       " '500 ',\n",
       " '411 ',\n",
       " '8519 ',\n",
       " '21 ',\n",
       " '21 ',\n",
       " '171 ',\n",
       " '7 ',\n",
       " '49 ',\n",
       " '12 ',\n",
       " '3 ',\n",
       " '21 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '7 ',\n",
       " '2 ',\n",
       " '11 ',\n",
       " '11 ',\n",
       " '173 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '3 ',\n",
       " '105 ',\n",
       " '25000 ',\n",
       " ' ',\n",
       " '18 ',\n",
       " '21000 ',\n",
       " '115 ',\n",
       " '21 ',\n",
       " '206 ',\n",
       " '43680 ',\n",
       " '8 ',\n",
       " '10 ',\n",
       " '59 ',\n",
       " '10 ',\n",
       " '5 ',\n",
       " '5 ',\n",
       " '1000 ',\n",
       " '138 ',\n",
       " ' ',\n",
       " '16 ',\n",
       " '2 ',\n",
       " '10 ',\n",
       " ' ',\n",
       " '8 ',\n",
       " '6 ',\n",
       " '129 ',\n",
       " '81 ',\n",
       " '12 ',\n",
       " '6 ',\n",
       " '22 ',\n",
       " '18 ',\n",
       " '9 ',\n",
       " '754 ',\n",
       " '14 ',\n",
       " '5 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '18 ',\n",
       " '7 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '7 ',\n",
       " '5 ',\n",
       " '6 ',\n",
       " '4 ',\n",
       " '18 ',\n",
       " '11 ',\n",
       " '25 ',\n",
       " ' ',\n",
       " '20 ',\n",
       " '12 ',\n",
       " '46 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '49 ',\n",
       " '11 ',\n",
       " '8 ',\n",
       " '54 ',\n",
       " '36 ',\n",
       " '3916 ',\n",
       " '710 ',\n",
       " '18 ',\n",
       " '8 ',\n",
       " '29 ',\n",
       " '7 ',\n",
       " '9 ',\n",
       " '37 ',\n",
       " '6 ',\n",
       " '1024 ',\n",
       " '1024 ',\n",
       " '14 ',\n",
       " '7 ',\n",
       " '8265 ',\n",
       " '29 ',\n",
       " '25 ',\n",
       " '3 ',\n",
       " '115 ',\n",
       " '1 ',\n",
       " '12 ',\n",
       " '13 ',\n",
       " '200000 ',\n",
       " '6 ',\n",
       " '21 ',\n",
       " '4 ',\n",
       " '2400 ',\n",
       " '175 ',\n",
       " '10 ',\n",
       " '4714 ',\n",
       " '23 ',\n",
       " '17 ',\n",
       " '2 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '280 ',\n",
       " '49 ',\n",
       " '3 ',\n",
       " '14 ',\n",
       " '19 ',\n",
       " ' ',\n",
       " '54 ',\n",
       " '8 ',\n",
       " '1087 ',\n",
       " '12 ',\n",
       " '3 ',\n",
       " '17 ',\n",
       " '8 ',\n",
       " '9 ',\n",
       " '12 ',\n",
       " '1656 ',\n",
       " '6 ',\n",
       " '2 ',\n",
       " '11 ',\n",
       " '533 ',\n",
       " '14 ',\n",
       " '84 ',\n",
       " '22 ',\n",
       " '16 ',\n",
       " '52 ',\n",
       " '19 ',\n",
       " '3 ',\n",
       " '14 ',\n",
       " '321 ',\n",
       " '13 ',\n",
       " '13 ',\n",
       " '55 ',\n",
       " '39 ',\n",
       " '4 ',\n",
       " '7 ',\n",
       " '79 ',\n",
       " '1 ',\n",
       " ' ',\n",
       " '14 ',\n",
       " '96 ',\n",
       " '21 ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '2 ',\n",
       " '69 ',\n",
       " '9 ',\n",
       " '124 ',\n",
       " '20 ',\n",
       " '25 ',\n",
       " '11 ',\n",
       " '19 ',\n",
       " '9 ',\n",
       " '9 ',\n",
       " '5 ',\n",
       " '7 ',\n",
       " '4006 ',\n",
       " '2 ',\n",
       " '19 ',\n",
       " '4 ',\n",
       " '13 ',\n",
       " '55 ',\n",
       " '1 ',\n",
       " '7842 ',\n",
       " '15 ',\n",
       " '15 ',\n",
       " '70 ',\n",
       " '7842 ',\n",
       " '4 ',\n",
       " '14 ',\n",
       " '17 ',\n",
       " '23 ',\n",
       " '321 ',\n",
       " '1068 ',\n",
       " '1068 ',\n",
       " '5 ',\n",
       " '6 ',\n",
       " '4 ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '7 ',\n",
       " '21 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '11 ',\n",
       " '21 ',\n",
       " '22 ',\n",
       " '2 ',\n",
       " '241 ',\n",
       " '33 ',\n",
       " '29 ',\n",
       " '7 ',\n",
       " '1 ',\n",
       " ' ',\n",
       " '4 ',\n",
       " '11 ',\n",
       " '47 ',\n",
       " '10 ',\n",
       " '3 ',\n",
       " '2 ',\n",
       " '632 ',\n",
       " '6826 ',\n",
       " '11 ',\n",
       " '525 ',\n",
       " '50 ',\n",
       " '7 ',\n",
       " '16 ',\n",
       " '2 ']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attribute=[]\n",
    "attribute=driver.find_elements(By.XPATH,\"//td[6]/p[@class='normal']\")\n",
    "for i in attribute:\n",
    "    Attribute.append(i.text)\n",
    "    \n",
    "Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4e7cd7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1995 ',\n",
       " '1996 ',\n",
       " ' ',\n",
       " '1998 ',\n",
       " '1998 ',\n",
       " '1992 ',\n",
       " '1987 ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1988 ',\n",
       " '1992 ',\n",
       " '1995 ',\n",
       " '1995 ',\n",
       " '1990 ',\n",
       " '1997 ',\n",
       " '1996 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1995 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1987 ',\n",
       " '1997 ',\n",
       " '1998 ',\n",
       " '1995 ',\n",
       " '1998 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1989 ',\n",
       " '1996 ',\n",
       " '1990 ',\n",
       " '1990 ',\n",
       " '1987 ',\n",
       " '1999 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " ' ',\n",
       " '1990 ',\n",
       " '1998 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1994 ',\n",
       " '1990 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1990 ',\n",
       " '1991 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1988 ',\n",
       " '1990 ',\n",
       " '1996 ',\n",
       " '1995 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1992 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1994 ',\n",
       " '1997 ',\n",
       " '1991 ',\n",
       " '1995 ',\n",
       " '1998 ',\n",
       " '1998 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1987 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '2001 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1997 ',\n",
       " '1991 ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1988 ',\n",
       " '1987 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1991 ',\n",
       " '1996 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2002 ',\n",
       " ' ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " ' ',\n",
       " '1998 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '1999 ',\n",
       " ' ',\n",
       " '2003 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '1997 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '1998 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1993 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1989 ',\n",
       " '2006 ',\n",
       " '2006 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2007 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2009 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2010 ',\n",
       " '2009 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2016 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2021 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2021 ',\n",
       " '2021 ']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Year=[]\n",
    "year=driver.find_elements(By.XPATH,\"//td[7]/p[@class='normal']\")\n",
    "for i in year:\n",
    "    Year.append(i.text)\n",
    "    \n",
    "Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "82b8a6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Name</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No Of Instance</th>\n",
       "      <th>No of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Data Name                 Task   \\\n",
       "0                                              Abalone       Classification    \n",
       "1                                                Adult       Classification    \n",
       "2                                            Annealing       Classification    \n",
       "3                         Anonymous Microsoft Web Data  Recommender-Systems    \n",
       "4                                           Arrhythmia       Classification    \n",
       "..                                                 ...                   ...   \n",
       "617  Influenza outbreak event prediction via Twitte...       Classification    \n",
       "618                      Turkish Music Emotion Dataset       Classification    \n",
       "619                      Maternal Health Risk Data Set       Classification    \n",
       "620                          Room Occupancy Estimation       Classification    \n",
       "621  Image Recognition Task Execution Times in Mobi...           Regression    \n",
       "\n",
       "                  Attribute Type No Of Instance No of Attributes   Year  \n",
       "0    Categorical, Integer, Real           4177                8   1995   \n",
       "1          Categorical, Integer          48842               14   1996   \n",
       "2    Categorical, Integer, Real            798               38          \n",
       "3                   Categorical          37711              294   1998   \n",
       "4    Categorical, Integer, Real            452              279   1998   \n",
       "..                           ...            ...              ...    ...  \n",
       "617               Integer, Real          75840              525   2020   \n",
       "618               Integer, Real            400               50   2020   \n",
       "619                                       1014                7   2020   \n",
       "620                        Real          10129               16   2021   \n",
       "621                        Real           4000                2   2021   \n",
       "\n",
       "[622 rows x 6 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Data Name\":DataSet_Name,\"Task \":Task,\"Attribute Type\":Attribute_type,\"No Of Instance\":Instances,\"No of Attributes\":Attribute,\"Year\":Year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9c490735",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee11f09d",
   "metadata": {},
   "source": [
    "Q6. Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e7988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re  # import regex\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56ccd1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Chromedriver\n",
    "driver=webdriver.Chrome(r'\"C:\\Users\\amits\\Desktop\\chromedriver_win32\\chromedriver.exe\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30f86df",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.billboard.com/'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe413e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "btn=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b279918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbutn=driver.find_element(By.XPATH,\"/html/body/div[3]/div[8]/div/div/div/ul/li[1]/ul/li[2]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "380bd3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90442976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anti-Hero',\n",
       " 'All I Want For Christmas Is You',\n",
       " \"Rockin' Around The Christmas Tree\",\n",
       " 'Unholy',\n",
       " 'Jingle Bell Rock',\n",
       " 'A Holly Jolly Christmas',\n",
       " 'Rich Flex',\n",
       " 'Bad Habit',\n",
       " \"It's The Most Wonderful Time Of The Year\",\n",
       " 'Last Christmas',\n",
       " \"I'm Good (Blue)\",\n",
       " 'The Christmas Song (Merry Christmas To You)',\n",
       " 'Feliz Navidad',\n",
       " 'As It Was',\n",
       " 'Die For You',\n",
       " 'Sleigh Ride',\n",
       " 'Underneath The Tree',\n",
       " 'Let It Snow, Let It Snow, Let It Snow',\n",
       " \"It's Beginning To Look A Lot Like Christmas\",\n",
       " 'Cuff It',\n",
       " 'Under The Influence',\n",
       " 'Lift Me Up',\n",
       " 'Christmas (Baby Please Come Home)',\n",
       " 'Santa Tell Me',\n",
       " 'You Proof',\n",
       " 'Super Freaky Girl',\n",
       " 'I Like You (A Happier Song)',\n",
       " 'Something In The Orange',\n",
       " \"It's Beginning To Look A Lot Like Christmas\",\n",
       " 'Deck The Halls',\n",
       " 'White Christmas',\n",
       " 'Wasted On You',\n",
       " 'Jingle Bells',\n",
       " 'Rudolph The Red-Nosed Reindeer',\n",
       " 'Just Wanna Rock',\n",
       " 'Made You Look',\n",
       " 'Tomorrow 2',\n",
       " 'Vegas',\n",
       " 'Here Comes Santa Claus (Right Down Santa Claus Lane)',\n",
       " 'Wait For U',\n",
       " 'Golden Hour',\n",
       " \"You're A Mean One, Mr. Grinch\",\n",
       " 'Blue Christmas',\n",
       " 'Titi Me Pregunto',\n",
       " \"I Ain't Worried\",\n",
       " 'Jimmy Cooks',\n",
       " 'Sunroof',\n",
       " 'About Damn Time',\n",
       " \"Santa Claus Is Comin' To Town\",\n",
       " 'She Had Me At Heads Carolina',\n",
       " 'Fall In Love',\n",
       " 'Lavender Haze',\n",
       " 'Spin Bout U',\n",
       " 'Until I Found You',\n",
       " 'Thank God',\n",
       " 'Circo Loco',\n",
       " \"Victoria's Secret\",\n",
       " 'On BS',\n",
       " 'Major Distribution',\n",
       " 'Son Of A Sinner',\n",
       " 'Rock And A Hard Place',\n",
       " 'What My World Spins Around',\n",
       " \"Star Walkin' (League Of Legends Worlds Anthem)\",\n",
       " 'Pussy & Millions',\n",
       " 'Wait In The Truck',\n",
       " 'Shirt',\n",
       " 'Hold Me Closer',\n",
       " 'Half Of Me',\n",
       " \"Don't Come Lookin'\",\n",
       " 'Bejeweled',\n",
       " 'Midnight Rain',\n",
       " 'Romantic Homicide',\n",
       " 'Maroon',\n",
       " 'Free Mind',\n",
       " 'Privileged Rappers',\n",
       " 'Whiskey On You',\n",
       " 'Billie Eilish.',\n",
       " 'Karma',\n",
       " 'Broke Boys',\n",
       " \"You're On Your Own, Kid\",\n",
       " 'BackOutsideBoyz',\n",
       " 'Heyy',\n",
       " 'Snow On The Beach',\n",
       " 'No Se Va',\n",
       " 'All Mine',\n",
       " 'California Breeze',\n",
       " 'Calm Down',\n",
       " 'Hours In Silence',\n",
       " 'Country On',\n",
       " 'Freestyle',\n",
       " 'Last Christmas',\n",
       " 'Jumbotron Shit Poppin',\n",
       " 'Pick Me Up',\n",
       " 'Heart Like A Truck',\n",
       " 'La Bachata',\n",
       " 'Someday At Christmas',\n",
       " 'Vigilante Shit',\n",
       " 'Forget Me',\n",
       " 'Going, Going, Gone',\n",
       " 'Miss You']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Song name\n",
    "Song_name=[]\n",
    "name=driver.find_elements(By.XPATH,\"//li[@class='lrv-u-width-100p']/ul/li/h3\")\n",
    "for i in name:\n",
    "    Song_name.append(i.text)\n",
    "    \n",
    "Song_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c73824c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Taylor Swift',\n",
       " '1',\n",
       " '1',\n",
       " '6',\n",
       " 'Mariah Carey',\n",
       " '5',\n",
       " '1',\n",
       " '54',\n",
       " 'Brenda Lee',\n",
       " '6',\n",
       " '2',\n",
       " '48',\n",
       " 'Sam Smith & Kim Petras',\n",
       " '3',\n",
       " '1',\n",
       " '10',\n",
       " 'Bobby Helms',\n",
       " '9',\n",
       " '3',\n",
       " '45',\n",
       " 'Burl Ives',\n",
       " '10',\n",
       " '4',\n",
       " '28',\n",
       " 'Drake & 21 Savage',\n",
       " '2',\n",
       " '2',\n",
       " '4',\n",
       " 'Steve Lacy',\n",
       " '4',\n",
       " '1',\n",
       " '22',\n",
       " 'Andy Williams',\n",
       " '19',\n",
       " '5',\n",
       " '29',\n",
       " 'Wham!',\n",
       " '23',\n",
       " '7',\n",
       " '27',\n",
       " 'David Guetta & Bebe Rexha',\n",
       " '7',\n",
       " '7',\n",
       " '14',\n",
       " 'Nat King Cole',\n",
       " '34',\n",
       " '11',\n",
       " '34',\n",
       " 'Jose Feliciano',\n",
       " '42',\n",
       " '6',\n",
       " '22',\n",
       " 'Harry Styles',\n",
       " '8',\n",
       " '1',\n",
       " '35',\n",
       " 'The Weeknd',\n",
       " '12',\n",
       " '12',\n",
       " '18',\n",
       " 'The Ronettes',\n",
       " '40',\n",
       " '10',\n",
       " '18',\n",
       " 'Kelly Clarkson',\n",
       " '48',\n",
       " '12',\n",
       " '17',\n",
       " 'Dean Martin',\n",
       " '41',\n",
       " '8',\n",
       " '21',\n",
       " 'Perry Como And The Fontane Sisters With Mitchell Ayres And His Orchestra',\n",
       " '43',\n",
       " '12',\n",
       " '14',\n",
       " 'Beyonce',\n",
       " '16',\n",
       " '13',\n",
       " '16',\n",
       " 'Chris Brown',\n",
       " '14',\n",
       " '14',\n",
       " '12',\n",
       " 'Rihanna',\n",
       " '11',\n",
       " '2',\n",
       " '5',\n",
       " 'Darlene Love',\n",
       " '-',\n",
       " '16',\n",
       " '13',\n",
       " 'Ariana Grande',\n",
       " '-',\n",
       " '17',\n",
       " '14',\n",
       " 'Morgan Wallen',\n",
       " '13',\n",
       " '5',\n",
       " '29',\n",
       " 'Nicki Minaj',\n",
       " '15',\n",
       " '1',\n",
       " '16',\n",
       " 'Post Malone Featuring Doja Cat',\n",
       " '18',\n",
       " '3',\n",
       " '26',\n",
       " 'Zach Bryan',\n",
       " '17',\n",
       " '12',\n",
       " '32',\n",
       " 'Michael Buble',\n",
       " '-',\n",
       " '20',\n",
       " '11',\n",
       " 'Nat King Cole',\n",
       " '-',\n",
       " '30',\n",
       " '4',\n",
       " 'Bing Crosby',\n",
       " '-',\n",
       " '12',\n",
       " '26',\n",
       " 'Morgan Wallen',\n",
       " '20',\n",
       " '9',\n",
       " '55',\n",
       " 'Frank Sinatra',\n",
       " '-',\n",
       " '33',\n",
       " '5',\n",
       " 'Gene Autry',\n",
       " '-',\n",
       " '16',\n",
       " '18',\n",
       " 'Lil Uzi Vert',\n",
       " '21',\n",
       " '21',\n",
       " '7',\n",
       " 'Meghan Trainor',\n",
       " '24',\n",
       " '24',\n",
       " '6',\n",
       " 'GloRilla & Cardi B',\n",
       " '22',\n",
       " '9',\n",
       " '10',\n",
       " 'Doja Cat',\n",
       " '25',\n",
       " '10',\n",
       " '26',\n",
       " 'Gene Autry',\n",
       " '-',\n",
       " '26',\n",
       " '11',\n",
       " 'Future Featuring Drake & Tems',\n",
       " '29',\n",
       " '1',\n",
       " '31',\n",
       " 'JVKE',\n",
       " '35',\n",
       " '35',\n",
       " '14',\n",
       " 'Thurl Ravenscroft',\n",
       " '-',\n",
       " '32',\n",
       " '5',\n",
       " 'Elvis Presley',\n",
       " '-',\n",
       " '33',\n",
       " '4',\n",
       " 'Bad Bunny',\n",
       " '28',\n",
       " '5',\n",
       " '30',\n",
       " 'OneRepublic',\n",
       " '27',\n",
       " '6',\n",
       " '25',\n",
       " 'Drake Featuring 21 Savage',\n",
       " '36',\n",
       " '1',\n",
       " '24',\n",
       " 'Nicky Youre & dazy',\n",
       " '33',\n",
       " '4',\n",
       " '27',\n",
       " 'Lizzo',\n",
       " '44',\n",
       " '1',\n",
       " '33',\n",
       " 'Jackson 5',\n",
       " '-',\n",
       " '41',\n",
       " '3',\n",
       " 'Cole Swindell',\n",
       " '38',\n",
       " '16',\n",
       " '27',\n",
       " 'Bailey Zimmerman',\n",
       " '49',\n",
       " '29',\n",
       " '31',\n",
       " 'Taylor Swift',\n",
       " '26',\n",
       " '2',\n",
       " '6',\n",
       " 'Drake & 21 Savage',\n",
       " '31',\n",
       " '5',\n",
       " '4',\n",
       " 'Stephen Sanchez',\n",
       " '45',\n",
       " '38',\n",
       " '22',\n",
       " 'Kane Brown With Katelyn Brown',\n",
       " '46',\n",
       " '22',\n",
       " '12',\n",
       " 'Drake & 21 Savage',\n",
       " '37',\n",
       " '8',\n",
       " '4',\n",
       " 'Jax',\n",
       " '59',\n",
       " '35',\n",
       " '18',\n",
       " 'Drake & 21 Savage',\n",
       " '39',\n",
       " '4',\n",
       " '4',\n",
       " 'Drake & 21 Savage',\n",
       " '30',\n",
       " '3',\n",
       " '4',\n",
       " 'Jelly Roll',\n",
       " '61',\n",
       " '31',\n",
       " '22',\n",
       " 'Bailey Zimmerman',\n",
       " '54',\n",
       " '24',\n",
       " '25',\n",
       " 'Jordan Davis',\n",
       " '55',\n",
       " '41',\n",
       " '16',\n",
       " 'Lil Nas X',\n",
       " '64',\n",
       " '32',\n",
       " '10',\n",
       " 'Drake & 21 Savage Featuring Travis Scott',\n",
       " '47',\n",
       " '6',\n",
       " '4',\n",
       " 'HARDY Featuring Lainey Wilson',\n",
       " '53',\n",
       " '51',\n",
       " '13',\n",
       " 'SZA',\n",
       " '63',\n",
       " '11',\n",
       " '5',\n",
       " 'Elton John & Britney Spears',\n",
       " '51',\n",
       " '6',\n",
       " '14',\n",
       " 'Thomas Rhett Featuring Riley Green',\n",
       " '56',\n",
       " '52',\n",
       " '15',\n",
       " 'Jackson Dean',\n",
       " '60',\n",
       " '50',\n",
       " '14',\n",
       " 'Taylor Swift',\n",
       " '50',\n",
       " '6',\n",
       " '6',\n",
       " 'Taylor Swift',\n",
       " '52',\n",
       " '5',\n",
       " '6',\n",
       " 'd4vd',\n",
       " '72',\n",
       " '33',\n",
       " '13',\n",
       " 'Taylor Swift',\n",
       " '58',\n",
       " '3',\n",
       " '6',\n",
       " 'Tems',\n",
       " '74',\n",
       " '46',\n",
       " '20',\n",
       " 'Drake & 21 Savage',\n",
       " '62',\n",
       " '7',\n",
       " '4',\n",
       " 'Nate Smith',\n",
       " '71',\n",
       " '44',\n",
       " '24',\n",
       " 'Armani White',\n",
       " '75',\n",
       " '58',\n",
       " '12',\n",
       " 'Taylor Swift',\n",
       " '65',\n",
       " '9',\n",
       " '6',\n",
       " 'Drake & 21 Savage',\n",
       " '68',\n",
       " '12',\n",
       " '4',\n",
       " 'Taylor Swift',\n",
       " '67',\n",
       " '8',\n",
       " '6',\n",
       " 'Drake',\n",
       " '66',\n",
       " '9',\n",
       " '4',\n",
       " 'Lil Baby',\n",
       " '80',\n",
       " '21',\n",
       " '8',\n",
       " 'Taylor Swift Featuring Lana Del Rey',\n",
       " '69',\n",
       " '4',\n",
       " '6',\n",
       " 'Grupo Frontera',\n",
       " '79',\n",
       " '57',\n",
       " '10',\n",
       " 'Brent Faiyaz',\n",
       " '93',\n",
       " '42',\n",
       " '17',\n",
       " 'Lil Baby',\n",
       " '81',\n",
       " '4',\n",
       " '7',\n",
       " 'Rema & Selena Gomez',\n",
       " '82',\n",
       " '74',\n",
       " '13',\n",
       " 'Drake & 21 Savage',\n",
       " '70',\n",
       " '11',\n",
       " '4',\n",
       " 'Luke Bryan',\n",
       " '83',\n",
       " '72',\n",
       " '15',\n",
       " 'Lil Baby',\n",
       " '90',\n",
       " '63',\n",
       " '12',\n",
       " 'Lauren Spencer-Smith',\n",
       " '-',\n",
       " '91',\n",
       " '1',\n",
       " 'Drake',\n",
       " '77',\n",
       " '16',\n",
       " '4',\n",
       " 'Gabby Barrett',\n",
       " '87',\n",
       " '69',\n",
       " '18',\n",
       " 'Lainey Wilson',\n",
       " '86',\n",
       " '86',\n",
       " '3',\n",
       " 'Manuel Turizo',\n",
       " '94',\n",
       " '67',\n",
       " '15',\n",
       " 'Lizzo',\n",
       " '-',\n",
       " '96',\n",
       " '1',\n",
       " 'Taylor Swift',\n",
       " '73',\n",
       " '10',\n",
       " '6',\n",
       " 'Lewis Capaldi',\n",
       " '-',\n",
       " '95',\n",
       " '6',\n",
       " 'Luke Combs',\n",
       " '98',\n",
       " '98',\n",
       " '3',\n",
       " 'Oliver Tree & Robin Schulz',\n",
       " '91',\n",
       " '84',\n",
       " '6']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Artist NAme\n",
    "Artist_name=[]\n",
    "name=driver.find_elements(By.XPATH,\"//li[@class='lrv-u-width-100p']/ul/li/span\")\n",
    "for i in name:\n",
    "     Artist_name.append(i.text)\n",
    "    \n",
    "    \n",
    "Artist_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6cfad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b99196c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered=[]\n",
    "nums=np.arange(1,101, 1)\n",
    "nums=list(nums.astype(str))                        #life saver code\n",
    "for name in Artist_name:\n",
    "    if name not in nums:\n",
    "        filtered.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5eb6efe9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Taylor Swift',\n",
       " 'Mariah Carey',\n",
       " 'Brenda Lee',\n",
       " 'Sam Smith & Kim Petras',\n",
       " 'Bobby Helms',\n",
       " 'Burl Ives',\n",
       " 'Drake & 21 Savage',\n",
       " 'Steve Lacy',\n",
       " 'Andy Williams',\n",
       " 'Wham!',\n",
       " 'David Guetta & Bebe Rexha',\n",
       " 'Nat King Cole',\n",
       " 'Jose Feliciano',\n",
       " 'Harry Styles',\n",
       " 'The Weeknd',\n",
       " 'The Ronettes',\n",
       " 'Kelly Clarkson',\n",
       " 'Dean Martin',\n",
       " 'Perry Como And The Fontane Sisters With Mitchell Ayres And His Orchestra',\n",
       " 'Beyonce',\n",
       " 'Chris Brown',\n",
       " 'Rihanna',\n",
       " 'Darlene Love',\n",
       " '-',\n",
       " 'Ariana Grande',\n",
       " '-',\n",
       " 'Morgan Wallen',\n",
       " 'Nicki Minaj',\n",
       " 'Post Malone Featuring Doja Cat',\n",
       " 'Zach Bryan',\n",
       " 'Michael Buble',\n",
       " '-',\n",
       " 'Nat King Cole',\n",
       " '-',\n",
       " 'Bing Crosby',\n",
       " '-',\n",
       " 'Morgan Wallen',\n",
       " 'Frank Sinatra',\n",
       " '-',\n",
       " 'Gene Autry',\n",
       " '-',\n",
       " 'Lil Uzi Vert',\n",
       " 'Meghan Trainor',\n",
       " 'GloRilla & Cardi B',\n",
       " 'Doja Cat',\n",
       " 'Gene Autry',\n",
       " '-',\n",
       " 'Future Featuring Drake & Tems',\n",
       " 'JVKE',\n",
       " 'Thurl Ravenscroft',\n",
       " '-',\n",
       " 'Elvis Presley',\n",
       " '-',\n",
       " 'Bad Bunny',\n",
       " 'OneRepublic',\n",
       " 'Drake Featuring 21 Savage',\n",
       " 'Nicky Youre & dazy',\n",
       " 'Lizzo',\n",
       " 'Jackson 5',\n",
       " '-',\n",
       " 'Cole Swindell',\n",
       " 'Bailey Zimmerman',\n",
       " 'Taylor Swift',\n",
       " 'Drake & 21 Savage',\n",
       " 'Stephen Sanchez',\n",
       " 'Kane Brown With Katelyn Brown',\n",
       " 'Drake & 21 Savage',\n",
       " 'Jax',\n",
       " 'Drake & 21 Savage',\n",
       " 'Drake & 21 Savage',\n",
       " 'Jelly Roll',\n",
       " 'Bailey Zimmerman',\n",
       " 'Jordan Davis',\n",
       " 'Lil Nas X',\n",
       " 'Drake & 21 Savage Featuring Travis Scott',\n",
       " 'HARDY Featuring Lainey Wilson',\n",
       " 'SZA',\n",
       " 'Elton John & Britney Spears',\n",
       " 'Thomas Rhett Featuring Riley Green',\n",
       " 'Jackson Dean',\n",
       " 'Taylor Swift',\n",
       " 'Taylor Swift',\n",
       " 'd4vd',\n",
       " 'Taylor Swift',\n",
       " 'Tems',\n",
       " 'Drake & 21 Savage',\n",
       " 'Nate Smith',\n",
       " 'Armani White',\n",
       " 'Taylor Swift',\n",
       " 'Drake & 21 Savage',\n",
       " 'Taylor Swift',\n",
       " 'Drake',\n",
       " 'Lil Baby',\n",
       " 'Taylor Swift Featuring Lana Del Rey',\n",
       " 'Grupo Frontera',\n",
       " 'Brent Faiyaz',\n",
       " 'Lil Baby',\n",
       " 'Rema & Selena Gomez',\n",
       " 'Drake & 21 Savage',\n",
       " 'Luke Bryan',\n",
       " 'Lil Baby',\n",
       " 'Lauren Spencer-Smith',\n",
       " '-',\n",
       " 'Drake',\n",
       " 'Gabby Barrett',\n",
       " 'Lainey Wilson',\n",
       " 'Manuel Turizo',\n",
       " 'Lizzo',\n",
       " '-',\n",
       " 'Taylor Swift',\n",
       " 'Lewis Capaldi',\n",
       " '-',\n",
       " 'Luke Combs',\n",
       " 'Oliver Tree & Robin Schulz']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cadb11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taylor Swift\n",
      "Mariah Carey\n",
      "Brenda Lee\n",
      "Sam Smith & Kim Petras\n",
      "Bobby Helms\n",
      "Burl Ives\n",
      "Drake & 21 Savage\n",
      "Steve Lacy\n",
      "Andy Williams\n",
      "Wham!\n",
      "David Guetta & Bebe Rexha\n",
      "Nat King Cole\n",
      "Jose Feliciano\n",
      "Harry Styles\n",
      "The Weeknd\n",
      "The Ronettes\n",
      "Kelly Clarkson\n",
      "Dean Martin\n",
      "Perry Como And The Fontane Sisters With Mitchell Ayres And His Orchestra\n",
      "Beyonce\n",
      "Chris Brown\n",
      "Rihanna\n",
      "Darlene Love\n",
      "-\n",
      "Ariana Grande\n",
      "-\n",
      "Morgan Wallen\n",
      "Nicki Minaj\n",
      "Post Malone Featuring Doja Cat\n",
      "Zach Bryan\n",
      "Michael Buble\n",
      "-\n",
      "Nat King Cole\n",
      "-\n",
      "Bing Crosby\n",
      "-\n",
      "Morgan Wallen\n",
      "Frank Sinatra\n",
      "-\n",
      "Gene Autry\n",
      "-\n",
      "Lil Uzi Vert\n",
      "Meghan Trainor\n",
      "GloRilla & Cardi B\n",
      "Doja Cat\n",
      "Gene Autry\n",
      "-\n",
      "Future Featuring Drake & Tems\n",
      "JVKE\n",
      "Thurl Ravenscroft\n",
      "-\n",
      "Elvis Presley\n",
      "-\n",
      "Bad Bunny\n",
      "OneRepublic\n",
      "Drake Featuring 21 Savage\n",
      "Nicky Youre & dazy\n",
      "Lizzo\n",
      "Jackson 5\n",
      "-\n",
      "Cole Swindell\n",
      "Bailey Zimmerman\n",
      "Taylor Swift\n",
      "Drake & 21 Savage\n",
      "Stephen Sanchez\n",
      "Kane Brown With Katelyn Brown\n",
      "Drake & 21 Savage\n",
      "Jax\n",
      "Drake & 21 Savage\n",
      "Drake & 21 Savage\n",
      "Jelly Roll\n",
      "Bailey Zimmerman\n",
      "Jordan Davis\n",
      "Lil Nas X\n",
      "Drake & 21 Savage Featuring Travis Scott\n",
      "HARDY Featuring Lainey Wilson\n",
      "SZA\n",
      "Elton John & Britney Spears\n",
      "Thomas Rhett Featuring Riley Green\n",
      "Jackson Dean\n",
      "Taylor Swift\n",
      "Taylor Swift\n",
      "d4vd\n",
      "Taylor Swift\n",
      "Tems\n",
      "Drake & 21 Savage\n",
      "Nate Smith\n",
      "Armani White\n",
      "Taylor Swift\n",
      "Drake & 21 Savage\n",
      "Taylor Swift\n",
      "Drake\n",
      "Lil Baby\n",
      "Taylor Swift Featuring Lana Del Rey\n",
      "Grupo Frontera\n",
      "Brent Faiyaz\n",
      "Lil Baby\n",
      "Rema & Selena Gomez\n",
      "Drake & 21 Savage\n",
      "Luke Bryan\n",
      "Lil Baby\n",
      "Lauren Spencer-Smith\n",
      "-\n",
      "Drake\n",
      "Gabby Barrett\n",
      "Lainey Wilson\n",
      "Manuel Turizo\n",
      "Lizzo\n",
      "-\n",
      "Taylor Swift\n",
      "Lewis Capaldi\n",
      "-\n",
      "Luke Combs\n",
      "Oliver Tree & Robin Schulz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for items in filtered[:]:\n",
    "    print(items)\n",
    "    if items=='-':\n",
    "        filtered.remove(items)\n",
    "    \n",
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "039e9a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b33d96e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '3',\n",
       " '4',\n",
       " '2',\n",
       " '1',\n",
       " '5',\n",
       " '7',\n",
       " '7',\n",
       " '11',\n",
       " '6',\n",
       " '1',\n",
       " '12',\n",
       " '10',\n",
       " '12',\n",
       " '8',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '2',\n",
       " '16',\n",
       " '17',\n",
       " '5',\n",
       " '1',\n",
       " '3',\n",
       " '12',\n",
       " '20',\n",
       " '30',\n",
       " '12',\n",
       " '9',\n",
       " '33',\n",
       " '16',\n",
       " '21',\n",
       " '24',\n",
       " '9',\n",
       " '10',\n",
       " '26',\n",
       " '1',\n",
       " '35',\n",
       " '32',\n",
       " '33',\n",
       " '5',\n",
       " '6',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '41',\n",
       " '16',\n",
       " '29',\n",
       " '2',\n",
       " '5',\n",
       " '38',\n",
       " '22',\n",
       " '8',\n",
       " '35',\n",
       " '4',\n",
       " '3',\n",
       " '31',\n",
       " '24',\n",
       " '41',\n",
       " '32',\n",
       " '6',\n",
       " '51',\n",
       " '11',\n",
       " '6',\n",
       " '52',\n",
       " '50',\n",
       " '6',\n",
       " '5',\n",
       " '33',\n",
       " '3',\n",
       " '46',\n",
       " '7',\n",
       " '44',\n",
       " '58',\n",
       " '9',\n",
       " '12',\n",
       " '8',\n",
       " '9',\n",
       " '21',\n",
       " '4',\n",
       " '57',\n",
       " '42',\n",
       " '4',\n",
       " '74',\n",
       " '11',\n",
       " '72',\n",
       " '63',\n",
       " '91',\n",
       " '16',\n",
       " '69',\n",
       " '86',\n",
       " '67',\n",
       " '96',\n",
       " '10',\n",
       " '95',\n",
       " '98',\n",
       " '84']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Peak Position\n",
    "Peak_pos=[]\n",
    "rank=driver.find_elements(By.XPATH,\"//li[@class='lrv-u-width-100p']/ul/li[5]\")\n",
    "for i in rank:\n",
    "    Peak_pos.append(i.text)\n",
    "    \n",
    "Peak_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c40394b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6',\n",
       " '54',\n",
       " '48',\n",
       " '10',\n",
       " '45',\n",
       " '28',\n",
       " '4',\n",
       " '22',\n",
       " '29',\n",
       " '27',\n",
       " '14',\n",
       " '34',\n",
       " '22',\n",
       " '35',\n",
       " '18',\n",
       " '18',\n",
       " '17',\n",
       " '21',\n",
       " '14',\n",
       " '16',\n",
       " '12',\n",
       " '5',\n",
       " '13',\n",
       " '14',\n",
       " '29',\n",
       " '16',\n",
       " '26',\n",
       " '32',\n",
       " '11',\n",
       " '4',\n",
       " '26',\n",
       " '55',\n",
       " '5',\n",
       " '18',\n",
       " '7',\n",
       " '6',\n",
       " '10',\n",
       " '26',\n",
       " '11',\n",
       " '31',\n",
       " '14',\n",
       " '5',\n",
       " '4',\n",
       " '30',\n",
       " '25',\n",
       " '24',\n",
       " '27',\n",
       " '33',\n",
       " '3',\n",
       " '27',\n",
       " '31',\n",
       " '6',\n",
       " '4',\n",
       " '22',\n",
       " '12',\n",
       " '4',\n",
       " '18',\n",
       " '4',\n",
       " '4',\n",
       " '22',\n",
       " '25',\n",
       " '16',\n",
       " '10',\n",
       " '4',\n",
       " '13',\n",
       " '5',\n",
       " '14',\n",
       " '15',\n",
       " '14',\n",
       " '6',\n",
       " '6',\n",
       " '13',\n",
       " '6',\n",
       " '20',\n",
       " '4',\n",
       " '24',\n",
       " '12',\n",
       " '6',\n",
       " '4',\n",
       " '6',\n",
       " '4',\n",
       " '8',\n",
       " '6',\n",
       " '10',\n",
       " '17',\n",
       " '7',\n",
       " '13',\n",
       " '4',\n",
       " '15',\n",
       " '12',\n",
       " '1',\n",
       " '4',\n",
       " '18',\n",
       " '3',\n",
       " '15',\n",
       " '1',\n",
       " '6',\n",
       " '6',\n",
       " '3',\n",
       " '6']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Week on Board\n",
    "week_on_bord=[]\n",
    "rank=driver.find_elements(By.XPATH,\"//li[@class='lrv-u-width-100p']/ul/li[6]\")\n",
    "for i in rank:\n",
    "    week_on_bord.append(i.text)\n",
    "    \n",
    "week_on_bord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3b44ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '5',\n",
       " '6',\n",
       " '3',\n",
       " '9',\n",
       " '10',\n",
       " '2',\n",
       " '4',\n",
       " '19',\n",
       " '23',\n",
       " '7',\n",
       " '34',\n",
       " '42',\n",
       " '8',\n",
       " '12',\n",
       " '40',\n",
       " '48',\n",
       " '41',\n",
       " '43',\n",
       " '16',\n",
       " '14',\n",
       " '11',\n",
       " '-',\n",
       " '-',\n",
       " '13',\n",
       " '15',\n",
       " '18',\n",
       " '17',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '20',\n",
       " '-',\n",
       " '-',\n",
       " '21',\n",
       " '24',\n",
       " '22',\n",
       " '25',\n",
       " '-',\n",
       " '29',\n",
       " '35',\n",
       " '-',\n",
       " '-',\n",
       " '28',\n",
       " '27',\n",
       " '36',\n",
       " '33',\n",
       " '44',\n",
       " '-',\n",
       " '38',\n",
       " '49',\n",
       " '26',\n",
       " '31',\n",
       " '45',\n",
       " '46',\n",
       " '37',\n",
       " '59',\n",
       " '39',\n",
       " '30',\n",
       " '61',\n",
       " '54',\n",
       " '55',\n",
       " '64',\n",
       " '47',\n",
       " '53',\n",
       " '63',\n",
       " '51',\n",
       " '56',\n",
       " '60',\n",
       " '50',\n",
       " '52',\n",
       " '72',\n",
       " '58',\n",
       " '74',\n",
       " '62',\n",
       " '71',\n",
       " '75',\n",
       " '65',\n",
       " '68',\n",
       " '67',\n",
       " '66',\n",
       " '80',\n",
       " '69',\n",
       " '79',\n",
       " '93',\n",
       " '81',\n",
       " '82',\n",
       " '70',\n",
       " '83',\n",
       " '90',\n",
       " '-',\n",
       " '77',\n",
       " '87',\n",
       " '86',\n",
       " '94',\n",
       " '-',\n",
       " '73',\n",
       " '-',\n",
       " '98',\n",
       " '91']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Last Week rank\n",
    "last_week=[]\n",
    "week=driver.find_elements(By.XPATH,\"//li[@class='lrv-u-width-100p']/ul/li[4]\")\n",
    "for i in week:\n",
    "    last_week.append(i.text)\n",
    "    \n",
    "last_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bff53e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataFrame\n",
    "BB=pd.DataFrame({\"Song Name\":Song_name,\"Artist Name\":filtered,\"Last Week Rank\":last_week,\"Peak Rank\":Peak_pos,\"Week On Board\":week_on_bord})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a14d0c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Week On Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rockin' Around The Christmas Tree</td>\n",
       "      <td>Brenda Lee</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unholy</td>\n",
       "      <td>Sam Smith &amp; Kim Petras</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jingle Bell Rock</td>\n",
       "      <td>Bobby Helms</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Someday At Christmas</td>\n",
       "      <td>Lizzo</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Vigilante Shit</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>73</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Forget Me</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>-</td>\n",
       "      <td>95</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Going, Going, Gone</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Miss You</td>\n",
       "      <td>Oliver Tree &amp; Robin Schulz</td>\n",
       "      <td>91</td>\n",
       "      <td>84</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Song Name                 Artist Name  \\\n",
       "0                           Anti-Hero                Taylor Swift   \n",
       "1     All I Want For Christmas Is You                Mariah Carey   \n",
       "2   Rockin' Around The Christmas Tree                  Brenda Lee   \n",
       "3                              Unholy      Sam Smith & Kim Petras   \n",
       "4                    Jingle Bell Rock                 Bobby Helms   \n",
       "..                                ...                         ...   \n",
       "95               Someday At Christmas                       Lizzo   \n",
       "96                     Vigilante Shit                Taylor Swift   \n",
       "97                          Forget Me               Lewis Capaldi   \n",
       "98                 Going, Going, Gone                  Luke Combs   \n",
       "99                           Miss You  Oliver Tree & Robin Schulz   \n",
       "\n",
       "   Last Week Rank Peak Rank Week On Board  \n",
       "0               1         1             6  \n",
       "1               5         1            54  \n",
       "2               6         2            48  \n",
       "3               3         1            10  \n",
       "4               9         3            45  \n",
       "..            ...       ...           ...  \n",
       "95              -        96             1  \n",
       "96             73        10             6  \n",
       "97              -        95             6  \n",
       "98             98        98             3  \n",
       "99             91        84             6  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f012bdc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
